{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training the ResNet-18 with CIFAR-10"]},{"cell_type":"markdown","metadata":{},"source":["This notebook trains the ResNet-18 network with the CIFAR-10 dataset in a deterministic fashion and stores the obtained weights."]},{"cell_type":"markdown","metadata":{},"source":["### 0. Import libraries and define settings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1VdY58D3KMZO"},"outputs":[],"source":["# import Python packages\n","import time\n","from tqdm import tqdm\n","from matplotlib import pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# allows to automatically update the imported modules\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1702728628184,"user":{"displayName":"Bindila Mihai-Bogdan","userId":"02772170685454837234"},"user_tz":-60},"id":"rhZQhrlxKSTK","outputId":"24523212-adef-4d95-b5be-8b374754d35f"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["use_cuda = True\n","\n","if use_cuda and torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","    \n","print(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Load and preprocess data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11578,"status":"ok","timestamp":1702728639758,"user":{"displayName":"Bindila Mihai-Bogdan","userId":"02772170685454837234"},"user_tz":-60},"id":"e1WVamZiKSXR","outputId":"c50561e9-7019-439f-d091-0af642de95e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_cifar/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 50265825.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data_cifar/cifar-10-python.tar.gz to ./data_cifar\n","Files already downloaded and verified\n"]}],"source":["transform_train = transforms.Compose(\n","    [\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ]\n",")\n","\n","transform_test = transforms.Compose(\n","    [\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ]\n",")\n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root=\"./data_cifar\", train=True, download=True, transform=transform_train\n",")\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root=\"./data_cifar\", train=False, download=True, transform=transform_test\n",")\n","\n","batch_size = 128\n","\n","c, w, h = 3, 32, 32\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n","\n","classes = (\n","    \"plane\",\n","    \"car\",\n","    \"bird\",\n","    \"cat\",\n","    \"deer\",\n","    \"dog\",\n","    \"frog\",\n","    \"horse\",\n","    \"ship\",\n","    \"truck\",\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Define architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HK1qpjYwUFqh"},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(\n","            in_channels, hidden_channels, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.batch1 = nn.BatchNorm2d(hidden_channels)\n","        self.relu = nn.ReLU()\n","        self.conv2 = nn.Conv2d(\n","            hidden_channels,\n","            out_channels,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1,\n","            bias=False,\n","        )\n","        self.batch2 = nn.BatchNorm2d(out_channels)\n","\n","        if in_channels != out_channels:\n","            self.skip_connection = nn.Sequential(\n","                nn.Conv2d(\n","                    in_channels, out_channels, kernel_size=1, stride=1, bias=False\n","                ),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","        else:\n","            self.skip_connection = lambda x: x\n","\n","    def forward(self, x):\n","        skip = self.skip_connection(x)\n","        x = self.conv1(x)\n","        x = self.batch1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.batch2(x)\n","        x = self.relu(x + skip)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qVgN9lPKSeC"},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, in_channels, out_size):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(\n","            in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        self.batch1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(3, stride=2, padding=1)\n","\n","        self.res_blocks = nn.ModuleList(\n","            [\n","                ResidualBlock(64, 64, 64),\n","                ResidualBlock(64, 64, 64),\n","                ResidualBlock(64, 128, 128),\n","                ResidualBlock(128, 128, 128),\n","                ResidualBlock(128, 256, 256),\n","                ResidualBlock(256, 256, 256),\n","                ResidualBlock(256, 512, 512),\n","                ResidualBlock(512, 512, 512),\n","            ]\n","        )\n","\n","        self.dense_layer = nn.Linear(512, out_size)\n","\n","        for module in self.modules():\n","            if isinstance(module, nn.Conv2d):\n","                nn.init.kaiming_normal_(\n","                    module.weight, mode=\"fan_out\", nonlinearity=\"relu\"\n","                )\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.batch1(x)\n","        x = self.relu(x)\n","        x = self.pool1(x)\n","        for block in self.res_blocks:\n","            x = block.forward(x)\n","        x = F.avg_pool2d(x, x.shape[2:])\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.dense_layer(x)\n","\n","        return x\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Train the network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIofWmkrT6Oh"},"outputs":[],"source":["net = ResNet(c, len(classes)).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcG_bfjoT7Dx","outputId":"5071a5c4-5a56-4c86-b044-4213a160c97f"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 0, time: 1.718s, loss: 2.473, train accuracy: 0.109\n","epoch: 0, time: 6.944s, loss: 1.855, train accuracy: 0.344\n","epoch: 0, time: 12.277s, loss: 1.789, train accuracy: 0.312\n","epoch: 0, time: 17.511s, loss: 1.617, train accuracy: 0.359\n","epoch: 0, time: 22.686s, loss: 1.559, train accuracy: 0.406\n","epoch: 0, time: 28.103s, loss: 1.631, train accuracy: 0.359\n","epoch: 0, time: 33.285s, loss: 1.417, train accuracy: 0.461\n","epoch: 0, time: 38.700s, loss: 1.438, train accuracy: 0.383\n","epoch: 0, time: 43.942s, loss: 1.477, train accuracy: 0.453\n","epoch: 0, time: 49.270s, loss: 1.357, train accuracy: 0.453\n","epoch: 0, time: 54.655s, loss: 1.302, train accuracy: 0.500\n","epoch: 0, time: 59.979s, loss: 1.531, train accuracy: 0.438\n","epoch: 0, time: 65.481s, loss: 1.251, train accuracy: 0.508\n","epoch: 0, time: 70.875s, loss: 1.364, train accuracy: 0.516\n","epoch: 0, time: 76.710s, loss: 1.332, train accuracy: 0.508\n","epoch: 0, time: 82.030s, loss: 1.072, train accuracy: 0.602\n","epoch: 0, time: 87.418s, loss: 1.287, train accuracy: 0.555\n","epoch: 0, time: 92.945s, loss: 1.209, train accuracy: 0.562\n","epoch: 0, time: 98.272s, loss: 1.197, train accuracy: 0.594\n","epoch: 0, time: 103.904s, loss: 1.506, train accuracy: 0.508\n","Accuracy on the test set: 0.523\n","epoch: 1, time: 114.779s, loss: 1.073, train accuracy: 0.594\n","epoch: 1, time: 120.266s, loss: 1.070, train accuracy: 0.586\n","epoch: 1, time: 125.782s, loss: 1.071, train accuracy: 0.633\n","epoch: 1, time: 131.394s, loss: 0.891, train accuracy: 0.688\n","epoch: 1, time: 136.927s, loss: 1.224, train accuracy: 0.562\n","epoch: 1, time: 142.636s, loss: 1.022, train accuracy: 0.617\n","epoch: 1, time: 148.188s, loss: 0.919, train accuracy: 0.664\n","epoch: 1, time: 153.994s, loss: 0.893, train accuracy: 0.641\n","epoch: 1, time: 159.578s, loss: 0.929, train accuracy: 0.641\n","epoch: 1, time: 165.339s, loss: 0.967, train accuracy: 0.641\n","epoch: 1, time: 171.095s, loss: 0.856, train accuracy: 0.727\n","epoch: 1, time: 176.782s, loss: 1.036, train accuracy: 0.594\n","epoch: 1, time: 182.589s, loss: 0.929, train accuracy: 0.656\n","epoch: 1, time: 188.239s, loss: 0.820, train accuracy: 0.711\n","epoch: 1, time: 194.065s, loss: 0.999, train accuracy: 0.641\n","epoch: 1, time: 199.704s, loss: 0.979, train accuracy: 0.609\n","epoch: 1, time: 205.544s, loss: 1.049, train accuracy: 0.641\n","epoch: 1, time: 211.145s, loss: 1.004, train accuracy: 0.656\n","epoch: 1, time: 216.856s, loss: 0.812, train accuracy: 0.711\n","epoch: 1, time: 222.549s, loss: 0.868, train accuracy: 0.734\n","Accuracy on the test set: 0.679\n","epoch: 2, time: 233.555s, loss: 0.804, train accuracy: 0.688\n","epoch: 2, time: 239.200s, loss: 0.839, train accuracy: 0.719\n","epoch: 2, time: 244.997s, loss: 0.842, train accuracy: 0.719\n","epoch: 2, time: 250.605s, loss: 0.831, train accuracy: 0.695\n","epoch: 2, time: 256.451s, loss: 0.875, train accuracy: 0.695\n","epoch: 2, time: 262.071s, loss: 0.830, train accuracy: 0.742\n","epoch: 2, time: 267.848s, loss: 0.934, train accuracy: 0.648\n","epoch: 2, time: 273.587s, loss: 0.871, train accuracy: 0.711\n","epoch: 2, time: 279.264s, loss: 0.676, train accuracy: 0.812\n","epoch: 2, time: 285.153s, loss: 0.792, train accuracy: 0.727\n","epoch: 2, time: 290.774s, loss: 0.786, train accuracy: 0.727\n","epoch: 2, time: 296.625s, loss: 0.959, train accuracy: 0.656\n","epoch: 2, time: 302.263s, loss: 0.839, train accuracy: 0.656\n","epoch: 2, time: 308.118s, loss: 0.743, train accuracy: 0.734\n","epoch: 2, time: 313.761s, loss: 0.794, train accuracy: 0.750\n","epoch: 2, time: 319.560s, loss: 0.657, train accuracy: 0.758\n","epoch: 2, time: 325.237s, loss: 0.797, train accuracy: 0.680\n","epoch: 2, time: 330.850s, loss: 0.726, train accuracy: 0.766\n","epoch: 2, time: 336.633s, loss: 0.787, train accuracy: 0.734\n","epoch: 2, time: 342.263s, loss: 0.891, train accuracy: 0.695\n","Accuracy on the test set: 0.711\n","epoch: 3, time: 353.187s, loss: 0.771, train accuracy: 0.750\n","epoch: 3, time: 358.987s, loss: 0.753, train accuracy: 0.750\n","epoch: 3, time: 364.620s, loss: 0.663, train accuracy: 0.758\n","epoch: 3, time: 370.358s, loss: 0.759, train accuracy: 0.742\n","epoch: 3, time: 376.071s, loss: 0.784, train accuracy: 0.758\n","epoch: 3, time: 381.689s, loss: 0.625, train accuracy: 0.781\n","epoch: 3, time: 387.451s, loss: 0.718, train accuracy: 0.781\n","epoch: 3, time: 393.097s, loss: 0.781, train accuracy: 0.727\n","epoch: 3, time: 398.955s, loss: 0.718, train accuracy: 0.758\n","epoch: 3, time: 404.587s, loss: 0.664, train accuracy: 0.758\n","epoch: 3, time: 410.409s, loss: 0.870, train accuracy: 0.711\n","epoch: 3, time: 416.324s, loss: 0.821, train accuracy: 0.680\n","epoch: 3, time: 422.086s, loss: 0.857, train accuracy: 0.711\n","epoch: 3, time: 427.769s, loss: 0.599, train accuracy: 0.805\n","epoch: 3, time: 433.441s, loss: 0.817, train accuracy: 0.758\n","epoch: 3, time: 439.196s, loss: 0.592, train accuracy: 0.797\n","epoch: 3, time: 444.840s, loss: 0.728, train accuracy: 0.734\n","epoch: 3, time: 450.686s, loss: 0.700, train accuracy: 0.734\n","epoch: 3, time: 456.310s, loss: 0.648, train accuracy: 0.820\n","epoch: 3, time: 462.133s, loss: 0.705, train accuracy: 0.750\n","Accuracy on the test set: 0.753\n","epoch: 4, time: 473.121s, loss: 0.617, train accuracy: 0.789\n","epoch: 4, time: 478.822s, loss: 0.599, train accuracy: 0.820\n","epoch: 4, time: 484.486s, loss: 0.646, train accuracy: 0.758\n","epoch: 4, time: 490.259s, loss: 0.609, train accuracy: 0.758\n","epoch: 4, time: 495.883s, loss: 0.502, train accuracy: 0.852\n","epoch: 4, time: 501.726s, loss: 0.570, train accuracy: 0.781\n","epoch: 4, time: 507.355s, loss: 0.483, train accuracy: 0.820\n","epoch: 4, time: 513.135s, loss: 0.693, train accuracy: 0.789\n","epoch: 4, time: 518.753s, loss: 0.622, train accuracy: 0.758\n","epoch: 4, time: 524.492s, loss: 0.644, train accuracy: 0.773\n","epoch: 4, time: 530.171s, loss: 0.652, train accuracy: 0.812\n","epoch: 4, time: 535.902s, loss: 0.651, train accuracy: 0.773\n","epoch: 4, time: 541.688s, loss: 0.679, train accuracy: 0.773\n","epoch: 4, time: 547.307s, loss: 0.645, train accuracy: 0.812\n","epoch: 4, time: 553.092s, loss: 0.639, train accuracy: 0.812\n","epoch: 4, time: 558.720s, loss: 0.474, train accuracy: 0.836\n","epoch: 4, time: 564.513s, loss: 0.549, train accuracy: 0.789\n","epoch: 4, time: 570.116s, loss: 0.604, train accuracy: 0.781\n","epoch: 4, time: 575.915s, loss: 0.516, train accuracy: 0.820\n","epoch: 4, time: 581.577s, loss: 0.522, train accuracy: 0.805\n","Accuracy on the test set: 0.772\n","epoch: 5, time: 592.628s, loss: 0.574, train accuracy: 0.844\n","epoch: 5, time: 598.264s, loss: 0.562, train accuracy: 0.781\n","epoch: 5, time: 604.053s, loss: 0.526, train accuracy: 0.812\n","epoch: 5, time: 609.670s, loss: 0.695, train accuracy: 0.758\n","epoch: 5, time: 615.493s, loss: 0.700, train accuracy: 0.742\n","epoch: 5, time: 621.117s, loss: 0.562, train accuracy: 0.797\n","epoch: 5, time: 626.892s, loss: 0.557, train accuracy: 0.805\n","epoch: 5, time: 632.540s, loss: 0.698, train accuracy: 0.766\n","epoch: 5, time: 638.296s, loss: 0.517, train accuracy: 0.828\n","epoch: 5, time: 644.073s, loss: 0.462, train accuracy: 0.820\n","epoch: 5, time: 649.697s, loss: 0.716, train accuracy: 0.758\n","epoch: 5, time: 655.544s, loss: 0.491, train accuracy: 0.797\n","epoch: 5, time: 661.194s, loss: 0.500, train accuracy: 0.820\n","epoch: 5, time: 667.004s, loss: 0.778, train accuracy: 0.750\n","epoch: 5, time: 672.629s, loss: 0.593, train accuracy: 0.828\n","epoch: 5, time: 678.417s, loss: 0.556, train accuracy: 0.758\n","epoch: 5, time: 684.112s, loss: 0.521, train accuracy: 0.820\n","epoch: 5, time: 689.839s, loss: 0.508, train accuracy: 0.883\n","epoch: 5, time: 695.576s, loss: 0.550, train accuracy: 0.797\n","epoch: 5, time: 701.201s, loss: 0.523, train accuracy: 0.828\n","Accuracy on the test set: 0.772\n","epoch: 6, time: 712.181s, loss: 0.486, train accuracy: 0.852\n","epoch: 6, time: 717.993s, loss: 0.332, train accuracy: 0.898\n","epoch: 6, time: 723.639s, loss: 0.438, train accuracy: 0.867\n","epoch: 6, time: 729.390s, loss: 0.443, train accuracy: 0.812\n","epoch: 6, time: 735.060s, loss: 0.462, train accuracy: 0.805\n","epoch: 6, time: 740.689s, loss: 0.421, train accuracy: 0.836\n","epoch: 6, time: 746.485s, loss: 0.439, train accuracy: 0.812\n","epoch: 6, time: 752.111s, loss: 0.487, train accuracy: 0.828\n","epoch: 6, time: 757.934s, loss: 0.484, train accuracy: 0.859\n","epoch: 6, time: 763.585s, loss: 0.468, train accuracy: 0.820\n","epoch: 6, time: 769.351s, loss: 0.529, train accuracy: 0.828\n","epoch: 6, time: 774.992s, loss: 0.513, train accuracy: 0.781\n","epoch: 6, time: 780.777s, loss: 0.388, train accuracy: 0.883\n","epoch: 6, time: 786.422s, loss: 0.475, train accuracy: 0.844\n","epoch: 6, time: 792.064s, loss: 0.571, train accuracy: 0.820\n","epoch: 6, time: 797.797s, loss: 0.501, train accuracy: 0.812\n","epoch: 6, time: 803.376s, loss: 0.302, train accuracy: 0.852\n","epoch: 6, time: 809.159s, loss: 0.613, train accuracy: 0.781\n","epoch: 6, time: 814.761s, loss: 0.460, train accuracy: 0.836\n","epoch: 6, time: 820.555s, loss: 0.443, train accuracy: 0.820\n","Accuracy on the test set: 0.784\n","epoch: 7, time: 831.499s, loss: 0.711, train accuracy: 0.797\n","epoch: 7, time: 837.232s, loss: 0.444, train accuracy: 0.828\n","epoch: 7, time: 842.945s, loss: 0.513, train accuracy: 0.828\n","epoch: 7, time: 848.702s, loss: 0.485, train accuracy: 0.789\n","epoch: 7, time: 854.304s, loss: 0.671, train accuracy: 0.742\n","epoch: 7, time: 860.087s, loss: 0.425, train accuracy: 0.867\n","epoch: 7, time: 865.707s, loss: 0.444, train accuracy: 0.828\n","epoch: 7, time: 871.797s, loss: 0.503, train accuracy: 0.820\n","epoch: 7, time: 877.534s, loss: 0.501, train accuracy: 0.852\n","epoch: 7, time: 883.184s, loss: 0.422, train accuracy: 0.836\n","epoch: 7, time: 888.914s, loss: 0.571, train accuracy: 0.797\n","epoch: 7, time: 894.526s, loss: 0.397, train accuracy: 0.852\n","epoch: 7, time: 900.374s, loss: 0.554, train accuracy: 0.805\n","epoch: 7, time: 905.969s, loss: 0.544, train accuracy: 0.789\n","epoch: 7, time: 911.745s, loss: 0.477, train accuracy: 0.836\n","epoch: 7, time: 917.360s, loss: 0.313, train accuracy: 0.891\n","epoch: 7, time: 923.111s, loss: 0.501, train accuracy: 0.820\n","epoch: 7, time: 928.825s, loss: 0.531, train accuracy: 0.797\n","epoch: 7, time: 934.475s, loss: 0.489, train accuracy: 0.852\n","epoch: 7, time: 940.244s, loss: 0.519, train accuracy: 0.805\n","Accuracy on the test set: 0.801\n","epoch: 8, time: 951.259s, loss: 0.531, train accuracy: 0.828\n","epoch: 8, time: 956.940s, loss: 0.625, train accuracy: 0.766\n","epoch: 8, time: 962.713s, loss: 0.487, train accuracy: 0.859\n","epoch: 8, time: 968.321s, loss: 0.383, train accuracy: 0.859\n","epoch: 8, time: 974.051s, loss: 0.345, train accuracy: 0.883\n","epoch: 8, time: 979.676s, loss: 0.466, train accuracy: 0.812\n","epoch: 8, time: 985.294s, loss: 0.447, train accuracy: 0.797\n","epoch: 8, time: 991.075s, loss: 0.447, train accuracy: 0.859\n","epoch: 8, time: 996.653s, loss: 0.418, train accuracy: 0.844\n","epoch: 8, time: 1002.419s, loss: 0.514, train accuracy: 0.781\n","epoch: 8, time: 1008.041s, loss: 0.443, train accuracy: 0.836\n","epoch: 8, time: 1013.861s, loss: 0.513, train accuracy: 0.859\n","epoch: 8, time: 1019.517s, loss: 0.449, train accuracy: 0.859\n","epoch: 8, time: 1025.284s, loss: 0.623, train accuracy: 0.742\n","epoch: 8, time: 1030.927s, loss: 0.481, train accuracy: 0.867\n","epoch: 8, time: 1036.599s, loss: 0.426, train accuracy: 0.852\n","epoch: 8, time: 1042.357s, loss: 0.407, train accuracy: 0.875\n","epoch: 8, time: 1047.960s, loss: 0.399, train accuracy: 0.836\n","epoch: 8, time: 1053.753s, loss: 0.522, train accuracy: 0.797\n","epoch: 8, time: 1059.339s, loss: 0.558, train accuracy: 0.820\n","Accuracy on the test set: 0.812\n","epoch: 9, time: 1070.424s, loss: 0.410, train accuracy: 0.859\n","epoch: 9, time: 1076.160s, loss: 0.468, train accuracy: 0.844\n","epoch: 9, time: 1081.847s, loss: 0.592, train accuracy: 0.789\n","epoch: 9, time: 1087.500s, loss: 0.423, train accuracy: 0.828\n","epoch: 9, time: 1093.304s, loss: 0.412, train accuracy: 0.891\n","epoch: 9, time: 1098.931s, loss: 0.515, train accuracy: 0.836\n","epoch: 9, time: 1104.754s, loss: 0.509, train accuracy: 0.805\n","epoch: 9, time: 1110.384s, loss: 0.406, train accuracy: 0.852\n","epoch: 9, time: 1116.216s, loss: 0.457, train accuracy: 0.875\n","epoch: 9, time: 1121.824s, loss: 0.415, train accuracy: 0.836\n","epoch: 9, time: 1127.588s, loss: 0.375, train accuracy: 0.852\n","epoch: 9, time: 1133.278s, loss: 0.346, train accuracy: 0.852\n","epoch: 9, time: 1138.975s, loss: 0.388, train accuracy: 0.883\n","epoch: 9, time: 1144.756s, loss: 0.535, train accuracy: 0.852\n","epoch: 9, time: 1150.356s, loss: 0.380, train accuracy: 0.891\n","epoch: 9, time: 1156.195s, loss: 0.318, train accuracy: 0.898\n","epoch: 9, time: 1161.820s, loss: 0.508, train accuracy: 0.812\n","epoch: 9, time: 1167.633s, loss: 0.461, train accuracy: 0.828\n","epoch: 9, time: 1173.274s, loss: 0.420, train accuracy: 0.867\n","epoch: 9, time: 1179.090s, loss: 0.232, train accuracy: 0.930\n","Accuracy on the test set: 0.832\n","epoch: 10, time: 1189.883s, loss: 0.340, train accuracy: 0.867\n","epoch: 10, time: 1195.678s, loss: 0.479, train accuracy: 0.844\n","epoch: 10, time: 1201.325s, loss: 0.426, train accuracy: 0.859\n","epoch: 10, time: 1207.128s, loss: 0.361, train accuracy: 0.883\n","epoch: 10, time: 1212.760s, loss: 0.293, train accuracy: 0.898\n","epoch: 10, time: 1218.567s, loss: 0.397, train accuracy: 0.867\n","epoch: 10, time: 1224.200s, loss: 0.569, train accuracy: 0.797\n","epoch: 10, time: 1229.921s, loss: 0.439, train accuracy: 0.859\n","epoch: 10, time: 1235.646s, loss: 0.412, train accuracy: 0.859\n","epoch: 10, time: 1241.341s, loss: 0.471, train accuracy: 0.836\n","epoch: 10, time: 1247.132s, loss: 0.480, train accuracy: 0.812\n","epoch: 10, time: 1252.748s, loss: 0.561, train accuracy: 0.812\n","epoch: 10, time: 1258.577s, loss: 0.434, train accuracy: 0.836\n","epoch: 10, time: 1264.222s, loss: 0.389, train accuracy: 0.867\n","epoch: 10, time: 1270.049s, loss: 0.553, train accuracy: 0.812\n","epoch: 10, time: 1275.665s, loss: 0.447, train accuracy: 0.852\n","epoch: 10, time: 1281.426s, loss: 0.484, train accuracy: 0.852\n","epoch: 10, time: 1287.117s, loss: 0.260, train accuracy: 0.898\n","epoch: 10, time: 1292.825s, loss: 0.342, train accuracy: 0.859\n","epoch: 10, time: 1298.603s, loss: 0.332, train accuracy: 0.875\n","Accuracy on the test set: 0.834\n","epoch: 11, time: 1309.717s, loss: 0.287, train accuracy: 0.898\n","epoch: 11, time: 1315.329s, loss: 0.253, train accuracy: 0.906\n","epoch: 11, time: 1321.152s, loss: 0.369, train accuracy: 0.852\n","epoch: 11, time: 1326.795s, loss: 0.337, train accuracy: 0.875\n","epoch: 11, time: 1332.545s, loss: 0.320, train accuracy: 0.883\n","epoch: 11, time: 1338.248s, loss: 0.459, train accuracy: 0.844\n","epoch: 11, time: 1344.187s, loss: 0.355, train accuracy: 0.898\n","epoch: 11, time: 1349.969s, loss: 0.307, train accuracy: 0.875\n","epoch: 11, time: 1355.634s, loss: 0.540, train accuracy: 0.828\n","epoch: 11, time: 1361.494s, loss: 0.412, train accuracy: 0.883\n","epoch: 11, time: 1367.124s, loss: 0.465, train accuracy: 0.844\n","epoch: 11, time: 1372.949s, loss: 0.443, train accuracy: 0.852\n","epoch: 11, time: 1378.697s, loss: 0.332, train accuracy: 0.875\n","epoch: 11, time: 1384.567s, loss: 0.312, train accuracy: 0.898\n","epoch: 11, time: 1390.209s, loss: 0.480, train accuracy: 0.844\n","epoch: 11, time: 1395.905s, loss: 0.393, train accuracy: 0.883\n","epoch: 11, time: 1401.650s, loss: 0.392, train accuracy: 0.875\n","epoch: 11, time: 1407.263s, loss: 0.368, train accuracy: 0.883\n","epoch: 11, time: 1413.105s, loss: 0.405, train accuracy: 0.875\n","epoch: 11, time: 1418.714s, loss: 0.395, train accuracy: 0.844\n","Accuracy on the test set: 0.823\n","epoch: 12, time: 1429.646s, loss: 0.347, train accuracy: 0.875\n","epoch: 12, time: 1435.357s, loss: 0.378, train accuracy: 0.852\n","epoch: 12, time: 1440.999s, loss: 0.258, train accuracy: 0.922\n","epoch: 12, time: 1446.695s, loss: 0.515, train accuracy: 0.836\n","epoch: 12, time: 1452.428s, loss: 0.228, train accuracy: 0.930\n","epoch: 12, time: 1458.058s, loss: 0.340, train accuracy: 0.875\n","epoch: 12, time: 1463.900s, loss: 0.391, train accuracy: 0.875\n","epoch: 12, time: 1469.506s, loss: 0.563, train accuracy: 0.789\n","epoch: 12, time: 1475.309s, loss: 0.278, train accuracy: 0.852\n","epoch: 12, time: 1480.924s, loss: 0.420, train accuracy: 0.883\n","epoch: 12, time: 1486.688s, loss: 0.356, train accuracy: 0.867\n","epoch: 12, time: 1492.312s, loss: 0.326, train accuracy: 0.875\n","epoch: 12, time: 1498.027s, loss: 0.390, train accuracy: 0.875\n","epoch: 12, time: 1503.736s, loss: 0.455, train accuracy: 0.852\n","epoch: 12, time: 1509.361s, loss: 0.312, train accuracy: 0.859\n","epoch: 12, time: 1515.128s, loss: 0.497, train accuracy: 0.852\n","epoch: 12, time: 1520.710s, loss: 0.223, train accuracy: 0.930\n","epoch: 12, time: 1526.485s, loss: 0.368, train accuracy: 0.867\n","epoch: 12, time: 1532.088s, loss: 0.232, train accuracy: 0.922\n","epoch: 12, time: 1537.892s, loss: 0.282, train accuracy: 0.891\n","Accuracy on the test set: 0.853\n","epoch: 13, time: 1548.692s, loss: 0.272, train accuracy: 0.859\n","epoch: 13, time: 1554.418s, loss: 0.247, train accuracy: 0.930\n","epoch: 13, time: 1560.047s, loss: 0.307, train accuracy: 0.906\n","epoch: 13, time: 1565.838s, loss: 0.293, train accuracy: 0.922\n","epoch: 13, time: 1571.489s, loss: 0.309, train accuracy: 0.930\n","epoch: 13, time: 1577.418s, loss: 0.393, train accuracy: 0.828\n","epoch: 13, time: 1583.045s, loss: 0.237, train accuracy: 0.930\n","epoch: 13, time: 1588.797s, loss: 0.371, train accuracy: 0.883\n","epoch: 13, time: 1594.462s, loss: 0.317, train accuracy: 0.859\n","epoch: 13, time: 1600.171s, loss: 0.371, train accuracy: 0.867\n","epoch: 13, time: 1605.903s, loss: 0.274, train accuracy: 0.898\n","epoch: 13, time: 1611.505s, loss: 0.407, train accuracy: 0.859\n","epoch: 13, time: 1617.324s, loss: 0.369, train accuracy: 0.859\n","epoch: 13, time: 1622.962s, loss: 0.453, train accuracy: 0.828\n","epoch: 13, time: 1628.783s, loss: 0.557, train accuracy: 0.773\n","epoch: 13, time: 1634.380s, loss: 0.349, train accuracy: 0.898\n","epoch: 13, time: 1640.165s, loss: 0.417, train accuracy: 0.852\n","epoch: 13, time: 1645.772s, loss: 0.246, train accuracy: 0.922\n","epoch: 13, time: 1651.459s, loss: 0.245, train accuracy: 0.922\n","epoch: 13, time: 1657.208s, loss: 0.301, train accuracy: 0.891\n","Accuracy on the test set: 0.832\n","epoch: 14, time: 1668.297s, loss: 0.250, train accuracy: 0.922\n","epoch: 14, time: 1673.947s, loss: 0.255, train accuracy: 0.914\n","epoch: 14, time: 1679.754s, loss: 0.249, train accuracy: 0.906\n","epoch: 14, time: 1685.402s, loss: 0.281, train accuracy: 0.914\n","epoch: 14, time: 1691.236s, loss: 0.305, train accuracy: 0.891\n","epoch: 14, time: 1696.875s, loss: 0.375, train accuracy: 0.867\n","epoch: 14, time: 1702.556s, loss: 0.243, train accuracy: 0.922\n","epoch: 14, time: 1708.294s, loss: 0.324, train accuracy: 0.898\n","epoch: 14, time: 1713.926s, loss: 0.436, train accuracy: 0.867\n","epoch: 14, time: 1719.698s, loss: 0.315, train accuracy: 0.867\n","epoch: 14, time: 1725.301s, loss: 0.342, train accuracy: 0.906\n","epoch: 14, time: 1731.087s, loss: 0.320, train accuracy: 0.875\n","epoch: 14, time: 1736.694s, loss: 0.205, train accuracy: 0.930\n","epoch: 14, time: 1742.503s, loss: 0.242, train accuracy: 0.906\n","epoch: 14, time: 1748.132s, loss: 0.248, train accuracy: 0.898\n","epoch: 14, time: 1753.854s, loss: 0.357, train accuracy: 0.859\n","epoch: 14, time: 1759.560s, loss: 0.310, train accuracy: 0.906\n","epoch: 14, time: 1765.152s, loss: 0.315, train accuracy: 0.883\n","epoch: 14, time: 1770.975s, loss: 0.500, train accuracy: 0.828\n","epoch: 14, time: 1776.602s, loss: 0.410, train accuracy: 0.859\n","Accuracy on the test set: 0.846\n","epoch: 15, time: 1787.600s, loss: 0.238, train accuracy: 0.875\n","epoch: 15, time: 1793.364s, loss: 0.302, train accuracy: 0.875\n","epoch: 15, time: 1799.008s, loss: 0.285, train accuracy: 0.898\n","epoch: 15, time: 1804.712s, loss: 0.284, train accuracy: 0.898\n","epoch: 15, time: 1810.448s, loss: 0.292, train accuracy: 0.898\n","epoch: 15, time: 1816.330s, loss: 0.231, train accuracy: 0.922\n","epoch: 15, time: 1822.156s, loss: 0.253, train accuracy: 0.930\n","epoch: 15, time: 1827.779s, loss: 0.416, train accuracy: 0.875\n","epoch: 15, time: 1833.573s, loss: 0.334, train accuracy: 0.852\n","epoch: 15, time: 1839.189s, loss: 0.389, train accuracy: 0.836\n","epoch: 15, time: 1845.033s, loss: 0.322, train accuracy: 0.891\n","epoch: 15, time: 1850.622s, loss: 0.361, train accuracy: 0.867\n","epoch: 15, time: 1856.316s, loss: 0.190, train accuracy: 0.938\n","epoch: 15, time: 1861.997s, loss: 0.328, train accuracy: 0.883\n","epoch: 15, time: 1867.604s, loss: 0.392, train accuracy: 0.836\n","epoch: 15, time: 1873.385s, loss: 0.314, train accuracy: 0.875\n","epoch: 15, time: 1878.998s, loss: 0.295, train accuracy: 0.875\n","epoch: 15, time: 1884.812s, loss: 0.308, train accuracy: 0.859\n","epoch: 15, time: 1890.423s, loss: 0.392, train accuracy: 0.852\n","epoch: 15, time: 1896.233s, loss: 0.335, train accuracy: 0.906\n","Accuracy on the test set: 0.855\n","epoch: 16, time: 1907.068s, loss: 0.425, train accuracy: 0.844\n","epoch: 16, time: 1912.824s, loss: 0.186, train accuracy: 0.945\n","epoch: 16, time: 1918.443s, loss: 0.197, train accuracy: 0.938\n","epoch: 16, time: 1924.254s, loss: 0.247, train accuracy: 0.938\n","epoch: 16, time: 1929.874s, loss: 0.179, train accuracy: 0.930\n","epoch: 16, time: 1935.649s, loss: 0.297, train accuracy: 0.891\n","epoch: 16, time: 1941.272s, loss: 0.264, train accuracy: 0.906\n","epoch: 16, time: 1947.052s, loss: 0.504, train accuracy: 0.867\n","epoch: 16, time: 1952.671s, loss: 0.229, train accuracy: 0.922\n","epoch: 16, time: 1958.370s, loss: 0.362, train accuracy: 0.844\n","epoch: 16, time: 1964.081s, loss: 0.385, train accuracy: 0.859\n","epoch: 16, time: 1969.691s, loss: 0.233, train accuracy: 0.914\n","epoch: 16, time: 1975.444s, loss: 0.271, train accuracy: 0.898\n","epoch: 16, time: 1981.054s, loss: 0.234, train accuracy: 0.914\n","epoch: 16, time: 1986.807s, loss: 0.445, train accuracy: 0.828\n","epoch: 16, time: 1992.401s, loss: 0.341, train accuracy: 0.867\n","epoch: 16, time: 1998.267s, loss: 0.291, train accuracy: 0.898\n","epoch: 16, time: 2003.869s, loss: 0.246, train accuracy: 0.914\n","epoch: 16, time: 2009.561s, loss: 0.234, train accuracy: 0.914\n","epoch: 16, time: 2015.289s, loss: 0.267, train accuracy: 0.906\n","Accuracy on the test set: 0.847\n","epoch: 17, time: 2026.377s, loss: 0.238, train accuracy: 0.922\n","epoch: 17, time: 2031.987s, loss: 0.311, train accuracy: 0.891\n","epoch: 17, time: 2037.783s, loss: 0.219, train accuracy: 0.922\n","epoch: 17, time: 2043.403s, loss: 0.153, train accuracy: 0.945\n","epoch: 17, time: 2049.153s, loss: 0.326, train accuracy: 0.883\n","epoch: 17, time: 2054.782s, loss: 0.415, train accuracy: 0.867\n","epoch: 17, time: 2060.451s, loss: 0.205, train accuracy: 0.930\n","epoch: 17, time: 2066.192s, loss: 0.421, train accuracy: 0.867\n","epoch: 17, time: 2071.844s, loss: 0.264, train accuracy: 0.938\n","epoch: 17, time: 2077.637s, loss: 0.241, train accuracy: 0.898\n","epoch: 17, time: 2083.262s, loss: 0.238, train accuracy: 0.898\n","epoch: 17, time: 2089.104s, loss: 0.153, train accuracy: 0.945\n","epoch: 17, time: 2094.709s, loss: 0.355, train accuracy: 0.883\n","epoch: 17, time: 2100.531s, loss: 0.286, train accuracy: 0.906\n","epoch: 17, time: 2106.179s, loss: 0.225, train accuracy: 0.922\n","epoch: 17, time: 2111.871s, loss: 0.252, train accuracy: 0.906\n","epoch: 17, time: 2117.583s, loss: 0.330, train accuracy: 0.867\n","epoch: 17, time: 2123.231s, loss: 0.364, train accuracy: 0.898\n","epoch: 17, time: 2129.041s, loss: 0.405, train accuracy: 0.828\n","epoch: 17, time: 2134.662s, loss: 0.307, train accuracy: 0.891\n","Accuracy on the test set: 0.845\n","epoch: 18, time: 2145.654s, loss: 0.281, train accuracy: 0.898\n","epoch: 18, time: 2151.385s, loss: 0.261, train accuracy: 0.906\n","epoch: 18, time: 2156.984s, loss: 0.210, train accuracy: 0.938\n","epoch: 18, time: 2162.654s, loss: 0.226, train accuracy: 0.906\n","epoch: 18, time: 2168.390s, loss: 0.475, train accuracy: 0.844\n","epoch: 18, time: 2173.962s, loss: 0.249, train accuracy: 0.938\n","epoch: 18, time: 2179.730s, loss: 0.255, train accuracy: 0.953\n","epoch: 18, time: 2185.308s, loss: 0.235, train accuracy: 0.906\n","epoch: 18, time: 2191.079s, loss: 0.195, train accuracy: 0.945\n","epoch: 18, time: 2196.683s, loss: 0.294, train accuracy: 0.883\n","epoch: 18, time: 2202.469s, loss: 0.322, train accuracy: 0.883\n","epoch: 18, time: 2208.098s, loss: 0.208, train accuracy: 0.922\n","epoch: 18, time: 2213.821s, loss: 0.211, train accuracy: 0.930\n","epoch: 18, time: 2219.555s, loss: 0.278, train accuracy: 0.898\n","epoch: 18, time: 2225.171s, loss: 0.241, train accuracy: 0.922\n","epoch: 18, time: 2230.966s, loss: 0.325, train accuracy: 0.883\n","epoch: 18, time: 2236.588s, loss: 0.295, train accuracy: 0.898\n","epoch: 18, time: 2242.380s, loss: 0.362, train accuracy: 0.875\n","epoch: 18, time: 2247.999s, loss: 0.381, train accuracy: 0.883\n","epoch: 18, time: 2253.797s, loss: 0.171, train accuracy: 0.930\n","Accuracy on the test set: 0.849\n","epoch: 19, time: 2264.583s, loss: 0.313, train accuracy: 0.891\n","epoch: 19, time: 2270.357s, loss: 0.247, train accuracy: 0.883\n","epoch: 19, time: 2275.969s, loss: 0.195, train accuracy: 0.914\n","epoch: 19, time: 2281.767s, loss: 0.259, train accuracy: 0.922\n","epoch: 19, time: 2287.380s, loss: 0.285, train accuracy: 0.906\n","epoch: 19, time: 2293.204s, loss: 0.314, train accuracy: 0.875\n","epoch: 19, time: 2299.122s, loss: 0.126, train accuracy: 0.969\n","epoch: 19, time: 2304.968s, loss: 0.259, train accuracy: 0.891\n","epoch: 19, time: 2310.582s, loss: 0.266, train accuracy: 0.883\n","epoch: 19, time: 2316.269s, loss: 0.275, train accuracy: 0.891\n","epoch: 19, time: 2321.974s, loss: 0.242, train accuracy: 0.914\n","epoch: 19, time: 2327.551s, loss: 0.161, train accuracy: 0.953\n","epoch: 19, time: 2333.308s, loss: 0.267, train accuracy: 0.891\n","epoch: 19, time: 2338.889s, loss: 0.301, train accuracy: 0.891\n","epoch: 19, time: 2344.634s, loss: 0.231, train accuracy: 0.906\n","epoch: 19, time: 2350.213s, loss: 0.229, train accuracy: 0.914\n","epoch: 19, time: 2355.963s, loss: 0.279, train accuracy: 0.906\n","epoch: 19, time: 2361.552s, loss: 0.266, train accuracy: 0.914\n","epoch: 19, time: 2367.243s, loss: 0.284, train accuracy: 0.898\n","epoch: 19, time: 2372.971s, loss: 0.204, train accuracy: 0.914\n","Accuracy on the test set: 0.843\n","epoch: 20, time: 2383.986s, loss: 0.201, train accuracy: 0.922\n","epoch: 20, time: 2389.597s, loss: 0.160, train accuracy: 0.945\n","epoch: 20, time: 2395.385s, loss: 0.170, train accuracy: 0.938\n","epoch: 20, time: 2400.984s, loss: 0.210, train accuracy: 0.945\n","epoch: 20, time: 2406.747s, loss: 0.269, train accuracy: 0.906\n","epoch: 20, time: 2412.326s, loss: 0.174, train accuracy: 0.953\n","epoch: 20, time: 2417.972s, loss: 0.207, train accuracy: 0.945\n","epoch: 20, time: 2423.676s, loss: 0.189, train accuracy: 0.922\n","epoch: 20, time: 2429.270s, loss: 0.271, train accuracy: 0.898\n","epoch: 20, time: 2435.006s, loss: 0.177, train accuracy: 0.938\n","epoch: 20, time: 2440.671s, loss: 0.279, train accuracy: 0.891\n","epoch: 20, time: 2446.515s, loss: 0.223, train accuracy: 0.914\n","epoch: 20, time: 2452.086s, loss: 0.240, train accuracy: 0.930\n","epoch: 20, time: 2457.801s, loss: 0.226, train accuracy: 0.930\n","epoch: 20, time: 2463.415s, loss: 0.255, train accuracy: 0.922\n","epoch: 20, time: 2469.052s, loss: 0.262, train accuracy: 0.875\n","epoch: 20, time: 2474.762s, loss: 0.292, train accuracy: 0.883\n","epoch: 20, time: 2480.373s, loss: 0.336, train accuracy: 0.883\n","epoch: 20, time: 2486.188s, loss: 0.169, train accuracy: 0.945\n","epoch: 20, time: 2491.782s, loss: 0.271, train accuracy: 0.891\n","Accuracy on the test set: 0.860\n","epoch: 21, time: 2502.721s, loss: 0.210, train accuracy: 0.906\n","epoch: 21, time: 2508.430s, loss: 0.219, train accuracy: 0.891\n","epoch: 21, time: 2514.072s, loss: 0.182, train accuracy: 0.922\n","epoch: 21, time: 2519.707s, loss: 0.383, train accuracy: 0.867\n","epoch: 21, time: 2525.442s, loss: 0.103, train accuracy: 0.953\n","epoch: 21, time: 2531.057s, loss: 0.147, train accuracy: 0.969\n","epoch: 21, time: 2536.897s, loss: 0.146, train accuracy: 0.961\n","epoch: 21, time: 2542.470s, loss: 0.283, train accuracy: 0.891\n","epoch: 21, time: 2548.238s, loss: 0.170, train accuracy: 0.930\n","epoch: 21, time: 2553.821s, loss: 0.175, train accuracy: 0.938\n","epoch: 21, time: 2559.522s, loss: 0.238, train accuracy: 0.938\n","epoch: 21, time: 2565.200s, loss: 0.226, train accuracy: 0.922\n","epoch: 21, time: 2570.810s, loss: 0.197, train accuracy: 0.945\n","epoch: 21, time: 2576.528s, loss: 0.276, train accuracy: 0.906\n","epoch: 21, time: 2582.115s, loss: 0.244, train accuracy: 0.906\n","epoch: 21, time: 2587.887s, loss: 0.232, train accuracy: 0.930\n","epoch: 21, time: 2593.489s, loss: 0.236, train accuracy: 0.922\n","epoch: 21, time: 2599.226s, loss: 0.231, train accuracy: 0.914\n","epoch: 21, time: 2604.839s, loss: 0.213, train accuracy: 0.914\n","epoch: 21, time: 2610.602s, loss: 0.239, train accuracy: 0.922\n","Accuracy on the test set: 0.865\n","epoch: 22, time: 2621.368s, loss: 0.186, train accuracy: 0.945\n","epoch: 22, time: 2627.128s, loss: 0.169, train accuracy: 0.953\n","epoch: 22, time: 2632.746s, loss: 0.259, train accuracy: 0.914\n","epoch: 22, time: 2638.540s, loss: 0.202, train accuracy: 0.914\n","epoch: 22, time: 2644.154s, loss: 0.134, train accuracy: 0.945\n","epoch: 22, time: 2649.918s, loss: 0.272, train accuracy: 0.898\n","epoch: 22, time: 2655.522s, loss: 0.259, train accuracy: 0.914\n","epoch: 22, time: 2661.217s, loss: 0.173, train accuracy: 0.953\n","epoch: 22, time: 2666.923s, loss: 0.247, train accuracy: 0.922\n","epoch: 22, time: 2672.498s, loss: 0.257, train accuracy: 0.922\n","epoch: 22, time: 2678.270s, loss: 0.180, train accuracy: 0.930\n","epoch: 22, time: 2683.848s, loss: 0.192, train accuracy: 0.922\n","epoch: 22, time: 2689.589s, loss: 0.148, train accuracy: 0.953\n","epoch: 22, time: 2695.195s, loss: 0.347, train accuracy: 0.867\n","epoch: 22, time: 2700.971s, loss: 0.178, train accuracy: 0.938\n","epoch: 22, time: 2706.586s, loss: 0.291, train accuracy: 0.875\n","epoch: 22, time: 2712.304s, loss: 0.186, train accuracy: 0.922\n","epoch: 22, time: 2718.004s, loss: 0.204, train accuracy: 0.953\n","epoch: 22, time: 2723.602s, loss: 0.285, train accuracy: 0.891\n","epoch: 22, time: 2729.387s, loss: 0.165, train accuracy: 0.945\n","Accuracy on the test set: 0.864\n","epoch: 23, time: 2740.373s, loss: 0.190, train accuracy: 0.938\n","epoch: 23, time: 2745.974s, loss: 0.285, train accuracy: 0.906\n","epoch: 23, time: 2751.728s, loss: 0.316, train accuracy: 0.914\n","epoch: 23, time: 2757.305s, loss: 0.184, train accuracy: 0.945\n","epoch: 23, time: 2763.047s, loss: 0.147, train accuracy: 0.938\n","epoch: 23, time: 2768.733s, loss: 0.178, train accuracy: 0.945\n","epoch: 23, time: 2774.322s, loss: 0.157, train accuracy: 0.938\n","epoch: 23, time: 2780.380s, loss: 0.145, train accuracy: 0.953\n","epoch: 23, time: 2786.084s, loss: 0.081, train accuracy: 0.969\n","epoch: 23, time: 2791.717s, loss: 0.230, train accuracy: 0.875\n","epoch: 23, time: 2797.433s, loss: 0.206, train accuracy: 0.938\n","epoch: 23, time: 2803.015s, loss: 0.240, train accuracy: 0.914\n","epoch: 23, time: 2808.829s, loss: 0.271, train accuracy: 0.898\n","epoch: 23, time: 2814.410s, loss: 0.301, train accuracy: 0.914\n","epoch: 23, time: 2820.216s, loss: 0.227, train accuracy: 0.914\n","epoch: 23, time: 2825.817s, loss: 0.268, train accuracy: 0.930\n","epoch: 23, time: 2831.557s, loss: 0.387, train accuracy: 0.875\n","epoch: 23, time: 2837.225s, loss: 0.247, train accuracy: 0.898\n","epoch: 23, time: 2842.860s, loss: 0.183, train accuracy: 0.938\n","epoch: 23, time: 2848.616s, loss: 0.147, train accuracy: 0.961\n","Accuracy on the test set: 0.867\n","epoch: 24, time: 2859.562s, loss: 0.101, train accuracy: 0.945\n","epoch: 24, time: 2865.123s, loss: 0.112, train accuracy: 0.977\n","epoch: 24, time: 2870.933s, loss: 0.145, train accuracy: 0.953\n","epoch: 24, time: 2876.527s, loss: 0.149, train accuracy: 0.953\n","epoch: 24, time: 2882.245s, loss: 0.239, train accuracy: 0.891\n","epoch: 24, time: 2887.945s, loss: 0.207, train accuracy: 0.938\n","epoch: 24, time: 2893.543s, loss: 0.236, train accuracy: 0.922\n","epoch: 24, time: 2899.306s, loss: 0.277, train accuracy: 0.906\n","epoch: 24, time: 2904.906s, loss: 0.152, train accuracy: 0.961\n","epoch: 24, time: 2910.657s, loss: 0.176, train accuracy: 0.930\n","epoch: 24, time: 2916.245s, loss: 0.269, train accuracy: 0.914\n","epoch: 24, time: 2921.993s, loss: 0.106, train accuracy: 0.961\n","epoch: 24, time: 2927.587s, loss: 0.175, train accuracy: 0.945\n","epoch: 24, time: 2933.256s, loss: 0.159, train accuracy: 0.938\n","epoch: 24, time: 2938.900s, loss: 0.123, train accuracy: 0.969\n","epoch: 24, time: 2944.513s, loss: 0.140, train accuracy: 0.930\n","epoch: 24, time: 2950.291s, loss: 0.258, train accuracy: 0.898\n","epoch: 24, time: 2955.865s, loss: 0.204, train accuracy: 0.922\n","epoch: 24, time: 2961.632s, loss: 0.270, train accuracy: 0.914\n","epoch: 24, time: 2967.229s, loss: 0.245, train accuracy: 0.930\n","Accuracy on the test set: 0.872\n","epoch: 25, time: 2978.277s, loss: 0.163, train accuracy: 0.938\n","epoch: 25, time: 2983.972s, loss: 0.206, train accuracy: 0.906\n","epoch: 25, time: 2989.702s, loss: 0.209, train accuracy: 0.906\n","epoch: 25, time: 2995.294s, loss: 0.323, train accuracy: 0.883\n","epoch: 25, time: 3001.069s, loss: 0.183, train accuracy: 0.930\n","epoch: 25, time: 3006.650s, loss: 0.230, train accuracy: 0.914\n","epoch: 25, time: 3012.426s, loss: 0.145, train accuracy: 0.938\n","epoch: 25, time: 3018.014s, loss: 0.120, train accuracy: 0.961\n","epoch: 25, time: 3023.749s, loss: 0.216, train accuracy: 0.914\n","epoch: 25, time: 3029.321s, loss: 0.188, train accuracy: 0.953\n","epoch: 25, time: 3035.000s, loss: 0.190, train accuracy: 0.953\n","epoch: 25, time: 3040.677s, loss: 0.217, train accuracy: 0.914\n","epoch: 25, time: 3046.261s, loss: 0.263, train accuracy: 0.891\n","epoch: 25, time: 3052.025s, loss: 0.194, train accuracy: 0.930\n","epoch: 25, time: 3057.628s, loss: 0.140, train accuracy: 0.969\n","epoch: 25, time: 3063.412s, loss: 0.093, train accuracy: 0.977\n","epoch: 25, time: 3068.990s, loss: 0.148, train accuracy: 0.953\n","epoch: 25, time: 3074.774s, loss: 0.179, train accuracy: 0.914\n","epoch: 25, time: 3080.351s, loss: 0.212, train accuracy: 0.922\n","epoch: 25, time: 3085.993s, loss: 0.162, train accuracy: 0.945\n","Accuracy on the test set: 0.881\n","epoch: 26, time: 3096.745s, loss: 0.202, train accuracy: 0.945\n","epoch: 26, time: 3102.559s, loss: 0.133, train accuracy: 0.953\n","epoch: 26, time: 3108.139s, loss: 0.189, train accuracy: 0.938\n","epoch: 26, time: 3113.893s, loss: 0.107, train accuracy: 0.961\n","epoch: 26, time: 3119.488s, loss: 0.186, train accuracy: 0.938\n","epoch: 26, time: 3125.292s, loss: 0.120, train accuracy: 0.953\n","epoch: 26, time: 3130.934s, loss: 0.197, train accuracy: 0.945\n","epoch: 26, time: 3136.624s, loss: 0.246, train accuracy: 0.914\n","epoch: 26, time: 3142.353s, loss: 0.151, train accuracy: 0.938\n","epoch: 26, time: 3147.958s, loss: 0.202, train accuracy: 0.922\n","epoch: 26, time: 3153.735s, loss: 0.174, train accuracy: 0.945\n","epoch: 26, time: 3159.336s, loss: 0.213, train accuracy: 0.945\n","epoch: 26, time: 3165.079s, loss: 0.214, train accuracy: 0.914\n","epoch: 26, time: 3170.663s, loss: 0.175, train accuracy: 0.930\n","epoch: 26, time: 3176.433s, loss: 0.118, train accuracy: 0.953\n","epoch: 26, time: 3182.043s, loss: 0.095, train accuracy: 0.984\n","epoch: 26, time: 3187.701s, loss: 0.118, train accuracy: 0.969\n","epoch: 26, time: 3193.391s, loss: 0.238, train accuracy: 0.930\n","epoch: 26, time: 3198.979s, loss: 0.144, train accuracy: 0.945\n","epoch: 26, time: 3204.738s, loss: 0.197, train accuracy: 0.914\n","Accuracy on the test set: 0.868\n","epoch: 27, time: 3215.804s, loss: 0.178, train accuracy: 0.938\n","epoch: 27, time: 3221.486s, loss: 0.214, train accuracy: 0.945\n","epoch: 27, time: 3227.239s, loss: 0.166, train accuracy: 0.953\n","epoch: 27, time: 3232.916s, loss: 0.168, train accuracy: 0.930\n","epoch: 27, time: 3238.613s, loss: 0.194, train accuracy: 0.945\n","epoch: 27, time: 3244.369s, loss: 0.234, train accuracy: 0.922\n","epoch: 27, time: 3249.997s, loss: 0.235, train accuracy: 0.922\n","epoch: 27, time: 3255.880s, loss: 0.161, train accuracy: 0.930\n","epoch: 27, time: 3261.659s, loss: 0.179, train accuracy: 0.945\n","epoch: 27, time: 3267.445s, loss: 0.093, train accuracy: 0.969\n","epoch: 27, time: 3273.071s, loss: 0.246, train accuracy: 0.930\n","epoch: 27, time: 3278.863s, loss: 0.110, train accuracy: 0.961\n","epoch: 27, time: 3284.463s, loss: 0.202, train accuracy: 0.914\n","epoch: 27, time: 3290.152s, loss: 0.127, train accuracy: 0.953\n","epoch: 27, time: 3295.881s, loss: 0.092, train accuracy: 0.969\n","epoch: 27, time: 3301.504s, loss: 0.203, train accuracy: 0.945\n","epoch: 27, time: 3307.314s, loss: 0.168, train accuracy: 0.938\n","epoch: 27, time: 3312.936s, loss: 0.094, train accuracy: 0.953\n","epoch: 27, time: 3318.747s, loss: 0.207, train accuracy: 0.938\n","epoch: 27, time: 3324.333s, loss: 0.152, train accuracy: 0.930\n","Accuracy on the test set: 0.880\n","epoch: 28, time: 3335.339s, loss: 0.150, train accuracy: 0.938\n","epoch: 28, time: 3341.033s, loss: 0.204, train accuracy: 0.930\n","epoch: 28, time: 3346.768s, loss: 0.078, train accuracy: 0.984\n","epoch: 28, time: 3352.366s, loss: 0.201, train accuracy: 0.930\n","epoch: 28, time: 3358.165s, loss: 0.224, train accuracy: 0.906\n","epoch: 28, time: 3363.767s, loss: 0.076, train accuracy: 0.984\n","epoch: 28, time: 3369.565s, loss: 0.111, train accuracy: 0.969\n","epoch: 28, time: 3375.203s, loss: 0.195, train accuracy: 0.938\n","epoch: 28, time: 3380.993s, loss: 0.137, train accuracy: 0.938\n","epoch: 28, time: 3386.592s, loss: 0.183, train accuracy: 0.930\n","epoch: 28, time: 3392.339s, loss: 0.145, train accuracy: 0.930\n","epoch: 28, time: 3398.047s, loss: 0.185, train accuracy: 0.938\n","epoch: 28, time: 3403.688s, loss: 0.112, train accuracy: 0.984\n","epoch: 28, time: 3409.496s, loss: 0.168, train accuracy: 0.938\n","epoch: 28, time: 3415.083s, loss: 0.203, train accuracy: 0.938\n","epoch: 28, time: 3420.856s, loss: 0.200, train accuracy: 0.914\n","epoch: 28, time: 3426.447s, loss: 0.167, train accuracy: 0.953\n","epoch: 28, time: 3432.234s, loss: 0.188, train accuracy: 0.922\n","epoch: 28, time: 3437.852s, loss: 0.084, train accuracy: 0.977\n","epoch: 28, time: 3443.528s, loss: 0.213, train accuracy: 0.938\n","Accuracy on the test set: 0.863\n","epoch: 29, time: 3454.405s, loss: 0.154, train accuracy: 0.906\n","epoch: 29, time: 3460.185s, loss: 0.134, train accuracy: 0.922\n","epoch: 29, time: 3465.790s, loss: 0.118, train accuracy: 0.977\n","epoch: 29, time: 3471.609s, loss: 0.140, train accuracy: 0.945\n","epoch: 29, time: 3477.216s, loss: 0.198, train accuracy: 0.922\n","epoch: 29, time: 3482.981s, loss: 0.035, train accuracy: 1.000\n","epoch: 29, time: 3488.608s, loss: 0.118, train accuracy: 0.953\n","epoch: 29, time: 3494.313s, loss: 0.116, train accuracy: 0.961\n","epoch: 29, time: 3500.026s, loss: 0.147, train accuracy: 0.953\n","epoch: 29, time: 3505.642s, loss: 0.121, train accuracy: 0.938\n","epoch: 29, time: 3511.436s, loss: 0.152, train accuracy: 0.930\n","epoch: 29, time: 3517.033s, loss: 0.097, train accuracy: 0.961\n","epoch: 29, time: 3522.887s, loss: 0.131, train accuracy: 0.938\n","epoch: 29, time: 3528.476s, loss: 0.153, train accuracy: 0.945\n","epoch: 29, time: 3534.290s, loss: 0.129, train accuracy: 0.961\n","epoch: 29, time: 3539.920s, loss: 0.215, train accuracy: 0.914\n","epoch: 29, time: 3545.606s, loss: 0.128, train accuracy: 0.953\n","epoch: 29, time: 3551.330s, loss: 0.184, train accuracy: 0.938\n","epoch: 29, time: 3556.939s, loss: 0.137, train accuracy: 0.961\n","epoch: 29, time: 3562.728s, loss: 0.126, train accuracy: 0.969\n","Accuracy on the test set: 0.878\n","epoch: 30, time: 3573.758s, loss: 0.120, train accuracy: 0.938\n","epoch: 30, time: 3579.348s, loss: 0.100, train accuracy: 0.969\n","epoch: 30, time: 3585.126s, loss: 0.094, train accuracy: 0.969\n","epoch: 30, time: 3590.695s, loss: 0.169, train accuracy: 0.930\n","epoch: 30, time: 3596.362s, loss: 0.080, train accuracy: 0.977\n","epoch: 30, time: 3602.050s, loss: 0.133, train accuracy: 0.930\n","epoch: 30, time: 3607.625s, loss: 0.140, train accuracy: 0.961\n","epoch: 30, time: 3613.405s, loss: 0.072, train accuracy: 0.984\n","epoch: 30, time: 3619.001s, loss: 0.224, train accuracy: 0.914\n","epoch: 30, time: 3624.743s, loss: 0.141, train accuracy: 0.961\n","epoch: 30, time: 3630.326s, loss: 0.157, train accuracy: 0.922\n","epoch: 30, time: 3636.091s, loss: 0.200, train accuracy: 0.938\n","epoch: 30, time: 3641.681s, loss: 0.201, train accuracy: 0.945\n","epoch: 30, time: 3647.358s, loss: 0.218, train accuracy: 0.930\n","epoch: 30, time: 3653.048s, loss: 0.130, train accuracy: 0.953\n","epoch: 30, time: 3658.653s, loss: 0.190, train accuracy: 0.945\n","epoch: 30, time: 3664.427s, loss: 0.173, train accuracy: 0.953\n","epoch: 30, time: 3670.025s, loss: 0.264, train accuracy: 0.891\n","epoch: 30, time: 3675.817s, loss: 0.085, train accuracy: 0.977\n","epoch: 30, time: 3681.405s, loss: 0.110, train accuracy: 0.969\n","Accuracy on the test set: 0.881\n","epoch: 31, time: 3692.460s, loss: 0.098, train accuracy: 0.961\n","epoch: 31, time: 3698.125s, loss: 0.168, train accuracy: 0.961\n","epoch: 31, time: 3703.830s, loss: 0.122, train accuracy: 0.953\n","epoch: 31, time: 3709.439s, loss: 0.124, train accuracy: 0.938\n","epoch: 31, time: 3715.234s, loss: 0.135, train accuracy: 0.953\n","epoch: 31, time: 3720.850s, loss: 0.127, train accuracy: 0.945\n","epoch: 31, time: 3726.670s, loss: 0.120, train accuracy: 0.953\n","epoch: 31, time: 3732.303s, loss: 0.125, train accuracy: 0.961\n","epoch: 31, time: 3738.080s, loss: 0.141, train accuracy: 0.953\n","epoch: 31, time: 3743.940s, loss: 0.141, train accuracy: 0.953\n","epoch: 31, time: 3749.654s, loss: 0.188, train accuracy: 0.938\n","epoch: 31, time: 3755.361s, loss: 0.215, train accuracy: 0.906\n","epoch: 31, time: 3760.954s, loss: 0.111, train accuracy: 0.938\n","epoch: 31, time: 3766.772s, loss: 0.160, train accuracy: 0.938\n","epoch: 31, time: 3772.404s, loss: 0.206, train accuracy: 0.922\n","epoch: 31, time: 3778.232s, loss: 0.093, train accuracy: 0.969\n","epoch: 31, time: 3783.847s, loss: 0.154, train accuracy: 0.953\n","epoch: 31, time: 3789.627s, loss: 0.150, train accuracy: 0.961\n","epoch: 31, time: 3795.237s, loss: 0.075, train accuracy: 0.984\n","epoch: 31, time: 3800.926s, loss: 0.119, train accuracy: 0.953\n","Accuracy on the test set: 0.887\n","epoch: 32, time: 3811.683s, loss: 0.098, train accuracy: 0.969\n","epoch: 32, time: 3817.464s, loss: 0.144, train accuracy: 0.953\n","epoch: 32, time: 3823.068s, loss: 0.209, train accuracy: 0.938\n","epoch: 32, time: 3828.904s, loss: 0.127, train accuracy: 0.961\n","epoch: 32, time: 3834.468s, loss: 0.056, train accuracy: 0.992\n","epoch: 32, time: 3840.207s, loss: 0.152, train accuracy: 0.945\n","epoch: 32, time: 3845.822s, loss: 0.140, train accuracy: 0.953\n","epoch: 32, time: 3851.479s, loss: 0.137, train accuracy: 0.953\n","epoch: 32, time: 3857.218s, loss: 0.132, train accuracy: 0.930\n","epoch: 32, time: 3862.814s, loss: 0.152, train accuracy: 0.930\n","epoch: 32, time: 3868.615s, loss: 0.147, train accuracy: 0.953\n","epoch: 32, time: 3874.205s, loss: 0.058, train accuracy: 0.984\n","epoch: 32, time: 3880.006s, loss: 0.087, train accuracy: 0.961\n","epoch: 32, time: 3885.603s, loss: 0.117, train accuracy: 0.961\n","epoch: 32, time: 3891.406s, loss: 0.132, train accuracy: 0.969\n","epoch: 32, time: 3897.033s, loss: 0.136, train accuracy: 0.945\n","epoch: 32, time: 3902.700s, loss: 0.176, train accuracy: 0.930\n","epoch: 32, time: 3908.391s, loss: 0.218, train accuracy: 0.930\n","epoch: 32, time: 3913.999s, loss: 0.160, train accuracy: 0.930\n","epoch: 32, time: 3919.780s, loss: 0.133, train accuracy: 0.961\n","Accuracy on the test set: 0.876\n","epoch: 33, time: 3930.939s, loss: 0.099, train accuracy: 0.961\n","epoch: 33, time: 3936.524s, loss: 0.106, train accuracy: 0.961\n","epoch: 33, time: 3942.314s, loss: 0.186, train accuracy: 0.938\n","epoch: 33, time: 3947.961s, loss: 0.073, train accuracy: 0.977\n","epoch: 33, time: 3953.613s, loss: 0.116, train accuracy: 0.961\n","epoch: 33, time: 3959.373s, loss: 0.128, train accuracy: 0.961\n","epoch: 33, time: 3964.960s, loss: 0.089, train accuracy: 0.969\n","epoch: 33, time: 3970.749s, loss: 0.094, train accuracy: 0.969\n","epoch: 33, time: 3976.352s, loss: 0.070, train accuracy: 0.977\n","epoch: 33, time: 3982.149s, loss: 0.080, train accuracy: 0.984\n","epoch: 33, time: 3987.751s, loss: 0.150, train accuracy: 0.914\n","epoch: 33, time: 3993.516s, loss: 0.231, train accuracy: 0.922\n","epoch: 33, time: 3999.174s, loss: 0.103, train accuracy: 0.977\n","epoch: 33, time: 4004.814s, loss: 0.129, train accuracy: 0.953\n","epoch: 33, time: 4010.506s, loss: 0.183, train accuracy: 0.945\n","epoch: 33, time: 4016.089s, loss: 0.059, train accuracy: 0.984\n","epoch: 33, time: 4021.912s, loss: 0.215, train accuracy: 0.945\n","epoch: 33, time: 4027.485s, loss: 0.111, train accuracy: 0.961\n","epoch: 33, time: 4033.274s, loss: 0.156, train accuracy: 0.938\n","epoch: 33, time: 4038.851s, loss: 0.153, train accuracy: 0.953\n","Accuracy on the test set: 0.886\n","epoch: 34, time: 4049.916s, loss: 0.147, train accuracy: 0.945\n","epoch: 34, time: 4055.518s, loss: 0.075, train accuracy: 0.969\n","epoch: 34, time: 4061.266s, loss: 0.227, train accuracy: 0.914\n","epoch: 34, time: 4066.879s, loss: 0.168, train accuracy: 0.930\n","epoch: 34, time: 4072.658s, loss: 0.075, train accuracy: 0.977\n","epoch: 34, time: 4078.253s, loss: 0.113, train accuracy: 0.961\n","epoch: 34, time: 4084.011s, loss: 0.081, train accuracy: 0.977\n","epoch: 34, time: 4089.617s, loss: 0.105, train accuracy: 0.969\n","epoch: 34, time: 4095.358s, loss: 0.114, train accuracy: 0.961\n","epoch: 34, time: 4101.074s, loss: 0.184, train accuracy: 0.945\n","epoch: 34, time: 4106.726s, loss: 0.155, train accuracy: 0.930\n","epoch: 34, time: 4112.497s, loss: 0.157, train accuracy: 0.945\n","epoch: 34, time: 4118.093s, loss: 0.152, train accuracy: 0.953\n","epoch: 34, time: 4123.875s, loss: 0.095, train accuracy: 0.969\n","epoch: 34, time: 4129.470s, loss: 0.129, train accuracy: 0.953\n","epoch: 34, time: 4135.275s, loss: 0.068, train accuracy: 0.984\n","epoch: 34, time: 4140.861s, loss: 0.193, train accuracy: 0.953\n","epoch: 34, time: 4146.588s, loss: 0.133, train accuracy: 0.953\n","epoch: 34, time: 4152.243s, loss: 0.145, train accuracy: 0.945\n","epoch: 34, time: 4157.896s, loss: 0.098, train accuracy: 0.961\n","Accuracy on the test set: 0.869\n","epoch: 35, time: 4168.744s, loss: 0.104, train accuracy: 0.969\n","epoch: 35, time: 4174.561s, loss: 0.168, train accuracy: 0.961\n","epoch: 35, time: 4180.171s, loss: 0.063, train accuracy: 0.977\n","epoch: 35, time: 4185.952s, loss: 0.132, train accuracy: 0.953\n","epoch: 35, time: 4191.574s, loss: 0.173, train accuracy: 0.953\n","epoch: 35, time: 4197.301s, loss: 0.114, train accuracy: 0.961\n","epoch: 35, time: 4202.987s, loss: 0.090, train accuracy: 0.969\n","epoch: 35, time: 4208.613s, loss: 0.162, train accuracy: 0.930\n","epoch: 35, time: 4214.412s, loss: 0.115, train accuracy: 0.953\n","epoch: 35, time: 4220.002s, loss: 0.069, train accuracy: 0.984\n","epoch: 35, time: 4225.794s, loss: 0.076, train accuracy: 0.969\n","epoch: 35, time: 4231.668s, loss: 0.128, train accuracy: 0.945\n","epoch: 35, time: 4237.420s, loss: 0.157, train accuracy: 0.938\n","epoch: 35, time: 4243.023s, loss: 0.167, train accuracy: 0.938\n","epoch: 35, time: 4248.763s, loss: 0.099, train accuracy: 0.969\n","epoch: 35, time: 4254.439s, loss: 0.138, train accuracy: 0.945\n","epoch: 35, time: 4260.119s, loss: 0.099, train accuracy: 0.961\n","epoch: 35, time: 4265.906s, loss: 0.185, train accuracy: 0.930\n","epoch: 35, time: 4271.522s, loss: 0.144, train accuracy: 0.953\n","epoch: 35, time: 4277.318s, loss: 0.135, train accuracy: 0.953\n","Accuracy on the test set: 0.886\n","epoch: 36, time: 4288.401s, loss: 0.105, train accuracy: 0.953\n","epoch: 36, time: 4293.996s, loss: 0.091, train accuracy: 0.953\n","epoch: 36, time: 4299.698s, loss: 0.086, train accuracy: 0.977\n","epoch: 36, time: 4305.339s, loss: 0.085, train accuracy: 0.992\n","epoch: 36, time: 4310.937s, loss: 0.102, train accuracy: 0.953\n","epoch: 36, time: 4316.680s, loss: 0.063, train accuracy: 0.977\n","epoch: 36, time: 4322.256s, loss: 0.095, train accuracy: 0.969\n","epoch: 36, time: 4328.017s, loss: 0.133, train accuracy: 0.961\n","epoch: 36, time: 4333.591s, loss: 0.184, train accuracy: 0.922\n","epoch: 36, time: 4339.335s, loss: 0.138, train accuracy: 0.945\n","epoch: 36, time: 4344.933s, loss: 0.308, train accuracy: 0.906\n","epoch: 36, time: 4350.670s, loss: 0.038, train accuracy: 0.992\n","epoch: 36, time: 4356.335s, loss: 0.115, train accuracy: 0.953\n","epoch: 36, time: 4361.950s, loss: 0.149, train accuracy: 0.961\n","epoch: 36, time: 4367.711s, loss: 0.157, train accuracy: 0.945\n","epoch: 36, time: 4373.312s, loss: 0.161, train accuracy: 0.930\n","epoch: 36, time: 4379.120s, loss: 0.054, train accuracy: 0.992\n","epoch: 36, time: 4384.723s, loss: 0.208, train accuracy: 0.938\n","epoch: 36, time: 4390.536s, loss: 0.100, train accuracy: 0.953\n","epoch: 36, time: 4396.178s, loss: 0.155, train accuracy: 0.945\n","Accuracy on the test set: 0.883\n","epoch: 37, time: 4407.205s, loss: 0.073, train accuracy: 0.984\n","epoch: 37, time: 4412.857s, loss: 0.079, train accuracy: 0.984\n","epoch: 37, time: 4418.686s, loss: 0.184, train accuracy: 0.922\n","epoch: 37, time: 4424.292s, loss: 0.068, train accuracy: 0.969\n","epoch: 37, time: 4430.054s, loss: 0.097, train accuracy: 0.977\n","epoch: 37, time: 4435.650s, loss: 0.071, train accuracy: 0.977\n","epoch: 37, time: 4441.414s, loss: 0.117, train accuracy: 0.938\n","epoch: 37, time: 4447.020s, loss: 0.127, train accuracy: 0.953\n","epoch: 37, time: 4452.705s, loss: 0.090, train accuracy: 0.961\n","epoch: 37, time: 4458.388s, loss: 0.097, train accuracy: 0.961\n","epoch: 37, time: 4463.971s, loss: 0.098, train accuracy: 0.953\n","epoch: 37, time: 4469.735s, loss: 0.104, train accuracy: 0.961\n","epoch: 37, time: 4475.329s, loss: 0.104, train accuracy: 0.953\n","epoch: 37, time: 4481.103s, loss: 0.097, train accuracy: 0.945\n","epoch: 37, time: 4486.674s, loss: 0.094, train accuracy: 0.953\n","epoch: 37, time: 4492.420s, loss: 0.197, train accuracy: 0.914\n","epoch: 37, time: 4498.005s, loss: 0.136, train accuracy: 0.945\n","epoch: 37, time: 4503.702s, loss: 0.169, train accuracy: 0.938\n","epoch: 37, time: 4509.388s, loss: 0.101, train accuracy: 0.953\n","epoch: 37, time: 4514.989s, loss: 0.069, train accuracy: 0.977\n","Accuracy on the test set: 0.861\n","epoch: 38, time: 4525.893s, loss: 0.097, train accuracy: 0.953\n","epoch: 38, time: 4531.695s, loss: 0.131, train accuracy: 0.961\n","epoch: 38, time: 4537.291s, loss: 0.060, train accuracy: 0.984\n","epoch: 38, time: 4543.106s, loss: 0.075, train accuracy: 0.977\n","epoch: 38, time: 4548.682s, loss: 0.103, train accuracy: 0.953\n","epoch: 38, time: 4554.358s, loss: 0.107, train accuracy: 0.953\n","epoch: 38, time: 4560.038s, loss: 0.049, train accuracy: 0.984\n","epoch: 38, time: 4565.642s, loss: 0.108, train accuracy: 0.969\n","epoch: 38, time: 4571.434s, loss: 0.038, train accuracy: 0.984\n","epoch: 38, time: 4577.027s, loss: 0.057, train accuracy: 0.977\n","epoch: 38, time: 4582.806s, loss: 0.064, train accuracy: 0.969\n","epoch: 38, time: 4588.434s, loss: 0.145, train accuracy: 0.938\n","epoch: 38, time: 4594.246s, loss: 0.078, train accuracy: 0.969\n","epoch: 38, time: 4599.851s, loss: 0.105, train accuracy: 0.977\n","epoch: 38, time: 4605.531s, loss: 0.123, train accuracy: 0.953\n","epoch: 38, time: 4611.229s, loss: 0.121, train accuracy: 0.938\n","epoch: 38, time: 4616.900s, loss: 0.100, train accuracy: 0.969\n","epoch: 38, time: 4622.687s, loss: 0.118, train accuracy: 0.930\n","epoch: 38, time: 4628.297s, loss: 0.106, train accuracy: 0.961\n","epoch: 38, time: 4634.123s, loss: 0.095, train accuracy: 0.969\n","Accuracy on the test set: 0.883\n","epoch: 39, time: 4645.108s, loss: 0.046, train accuracy: 0.992\n","epoch: 39, time: 4650.730s, loss: 0.184, train accuracy: 0.930\n","epoch: 39, time: 4656.463s, loss: 0.054, train accuracy: 0.984\n","epoch: 39, time: 4662.149s, loss: 0.069, train accuracy: 0.977\n","epoch: 39, time: 4667.755s, loss: 0.077, train accuracy: 0.977\n","epoch: 39, time: 4673.563s, loss: 0.063, train accuracy: 0.969\n","epoch: 39, time: 4679.157s, loss: 0.085, train accuracy: 0.977\n","epoch: 39, time: 4684.980s, loss: 0.078, train accuracy: 0.969\n","epoch: 39, time: 4690.567s, loss: 0.058, train accuracy: 0.984\n","epoch: 39, time: 4696.350s, loss: 0.183, train accuracy: 0.938\n","epoch: 39, time: 4701.961s, loss: 0.056, train accuracy: 0.984\n","epoch: 39, time: 4707.621s, loss: 0.071, train accuracy: 0.969\n","epoch: 39, time: 4713.364s, loss: 0.148, train accuracy: 0.945\n","epoch: 39, time: 4718.966s, loss: 0.084, train accuracy: 0.969\n","epoch: 39, time: 4724.744s, loss: 0.181, train accuracy: 0.938\n","epoch: 39, time: 4730.594s, loss: 0.062, train accuracy: 0.984\n","epoch: 39, time: 4736.352s, loss: 0.129, train accuracy: 0.961\n","epoch: 39, time: 4741.955s, loss: 0.050, train accuracy: 0.992\n","epoch: 39, time: 4747.725s, loss: 0.064, train accuracy: 0.977\n","epoch: 39, time: 4753.326s, loss: 0.042, train accuracy: 0.992\n","Accuracy on the test set: 0.884\n","epoch: 40, time: 4764.392s, loss: 0.142, train accuracy: 0.977\n","epoch: 40, time: 4769.987s, loss: 0.130, train accuracy: 0.961\n","epoch: 40, time: 4775.780s, loss: 0.147, train accuracy: 0.945\n","epoch: 40, time: 4781.408s, loss: 0.082, train accuracy: 0.969\n","epoch: 40, time: 4787.144s, loss: 0.099, train accuracy: 0.961\n","epoch: 40, time: 4792.736s, loss: 0.032, train accuracy: 1.000\n","epoch: 40, time: 4798.510s, loss: 0.148, train accuracy: 0.961\n","epoch: 40, time: 4804.107s, loss: 0.118, train accuracy: 0.945\n","epoch: 40, time: 4809.785s, loss: 0.060, train accuracy: 0.984\n","epoch: 40, time: 4815.492s, loss: 0.116, train accuracy: 0.938\n","epoch: 40, time: 4821.095s, loss: 0.118, train accuracy: 0.969\n","epoch: 40, time: 4826.846s, loss: 0.146, train accuracy: 0.953\n","epoch: 40, time: 4832.464s, loss: 0.133, train accuracy: 0.953\n","epoch: 40, time: 4838.217s, loss: 0.091, train accuracy: 0.969\n","epoch: 40, time: 4843.834s, loss: 0.122, train accuracy: 0.961\n","epoch: 40, time: 4849.609s, loss: 0.098, train accuracy: 0.961\n","epoch: 40, time: 4855.199s, loss: 0.041, train accuracy: 0.992\n","epoch: 40, time: 4860.854s, loss: 0.068, train accuracy: 0.961\n","epoch: 40, time: 4866.571s, loss: 0.098, train accuracy: 0.961\n","epoch: 40, time: 4872.209s, loss: 0.173, train accuracy: 0.969\n","Accuracy on the test set: 0.884\n","epoch: 41, time: 4883.089s, loss: 0.060, train accuracy: 0.984\n","epoch: 41, time: 4888.860s, loss: 0.085, train accuracy: 0.969\n","epoch: 41, time: 4894.472s, loss: 0.099, train accuracy: 0.977\n","epoch: 41, time: 4900.201s, loss: 0.051, train accuracy: 0.977\n","epoch: 41, time: 4905.805s, loss: 0.052, train accuracy: 0.984\n","epoch: 41, time: 4911.441s, loss: 0.081, train accuracy: 0.961\n","epoch: 41, time: 4917.113s, loss: 0.096, train accuracy: 0.969\n","epoch: 41, time: 4922.696s, loss: 0.083, train accuracy: 0.961\n","epoch: 41, time: 4928.473s, loss: 0.037, train accuracy: 0.992\n","epoch: 41, time: 4934.085s, loss: 0.050, train accuracy: 0.984\n","epoch: 41, time: 4939.840s, loss: 0.108, train accuracy: 0.938\n","epoch: 41, time: 4945.435s, loss: 0.103, train accuracy: 0.961\n","epoch: 41, time: 4951.204s, loss: 0.069, train accuracy: 0.984\n","epoch: 41, time: 4956.828s, loss: 0.092, train accuracy: 0.969\n","epoch: 41, time: 4962.530s, loss: 0.171, train accuracy: 0.930\n","epoch: 41, time: 4968.282s, loss: 0.242, train accuracy: 0.930\n","epoch: 41, time: 4973.884s, loss: 0.171, train accuracy: 0.953\n","epoch: 41, time: 4979.649s, loss: 0.181, train accuracy: 0.953\n","epoch: 41, time: 4985.256s, loss: 0.170, train accuracy: 0.922\n","epoch: 41, time: 4991.068s, loss: 0.178, train accuracy: 0.922\n","Accuracy on the test set: 0.875\n","epoch: 42, time: 5002.043s, loss: 0.097, train accuracy: 0.953\n","epoch: 42, time: 5007.696s, loss: 0.071, train accuracy: 0.969\n","epoch: 42, time: 5013.352s, loss: 0.096, train accuracy: 0.969\n","epoch: 42, time: 5019.091s, loss: 0.105, train accuracy: 0.984\n","epoch: 42, time: 5024.684s, loss: 0.131, train accuracy: 0.945\n","epoch: 42, time: 5030.449s, loss: 0.127, train accuracy: 0.961\n","epoch: 42, time: 5036.018s, loss: 0.088, train accuracy: 0.969\n","epoch: 42, time: 5041.767s, loss: 0.091, train accuracy: 0.984\n","epoch: 42, time: 5047.320s, loss: 0.041, train accuracy: 0.984\n","epoch: 42, time: 5053.037s, loss: 0.078, train accuracy: 0.953\n","epoch: 42, time: 5058.662s, loss: 0.119, train accuracy: 0.945\n","epoch: 42, time: 5064.267s, loss: 0.094, train accuracy: 0.961\n","epoch: 42, time: 5069.964s, loss: 0.076, train accuracy: 0.953\n","epoch: 42, time: 5075.559s, loss: 0.123, train accuracy: 0.953\n","epoch: 42, time: 5081.320s, loss: 0.070, train accuracy: 0.977\n","epoch: 42, time: 5086.922s, loss: 0.090, train accuracy: 0.977\n","epoch: 42, time: 5092.702s, loss: 0.081, train accuracy: 0.977\n","epoch: 42, time: 5098.313s, loss: 0.104, train accuracy: 0.977\n","epoch: 42, time: 5104.047s, loss: 0.088, train accuracy: 0.969\n","epoch: 42, time: 5109.667s, loss: 0.108, train accuracy: 0.953\n","Accuracy on the test set: 0.885\n","epoch: 43, time: 5120.718s, loss: 0.053, train accuracy: 0.969\n","epoch: 43, time: 5126.293s, loss: 0.083, train accuracy: 0.977\n","epoch: 43, time: 5132.049s, loss: 0.089, train accuracy: 0.969\n","epoch: 43, time: 5137.638s, loss: 0.124, train accuracy: 0.953\n","epoch: 43, time: 5143.489s, loss: 0.138, train accuracy: 0.945\n","epoch: 43, time: 5149.085s, loss: 0.077, train accuracy: 0.961\n","epoch: 43, time: 5154.787s, loss: 0.096, train accuracy: 0.961\n","epoch: 43, time: 5160.465s, loss: 0.034, train accuracy: 1.000\n","epoch: 43, time: 5166.045s, loss: 0.068, train accuracy: 0.984\n","epoch: 43, time: 5171.832s, loss: 0.080, train accuracy: 0.977\n","epoch: 43, time: 5177.421s, loss: 0.099, train accuracy: 0.969\n","epoch: 43, time: 5183.168s, loss: 0.118, train accuracy: 0.961\n","epoch: 43, time: 5188.733s, loss: 0.119, train accuracy: 0.961\n","epoch: 43, time: 5194.534s, loss: 0.066, train accuracy: 0.977\n","epoch: 43, time: 5200.124s, loss: 0.151, train accuracy: 0.969\n","epoch: 43, time: 5205.832s, loss: 0.117, train accuracy: 0.953\n","epoch: 43, time: 5211.483s, loss: 0.071, train accuracy: 0.977\n","epoch: 43, time: 5217.069s, loss: 0.104, train accuracy: 0.969\n","epoch: 43, time: 5222.861s, loss: 0.125, train accuracy: 0.945\n","epoch: 43, time: 5228.439s, loss: 0.112, train accuracy: 0.961\n","Accuracy on the test set: 0.894\n","epoch: 44, time: 5239.863s, loss: 0.098, train accuracy: 0.961\n","epoch: 44, time: 5245.635s, loss: 0.105, train accuracy: 0.961\n","epoch: 44, time: 5251.250s, loss: 0.109, train accuracy: 0.969\n","epoch: 44, time: 5256.975s, loss: 0.060, train accuracy: 0.984\n","epoch: 44, time: 5262.645s, loss: 0.103, train accuracy: 0.953\n","epoch: 44, time: 5268.311s, loss: 0.060, train accuracy: 0.977\n","epoch: 44, time: 5274.117s, loss: 0.077, train accuracy: 0.953\n","epoch: 44, time: 5279.726s, loss: 0.123, train accuracy: 0.961\n","epoch: 44, time: 5285.524s, loss: 0.121, train accuracy: 0.969\n","epoch: 44, time: 5291.100s, loss: 0.152, train accuracy: 0.945\n","epoch: 44, time: 5296.970s, loss: 0.049, train accuracy: 0.992\n","epoch: 44, time: 5302.554s, loss: 0.097, train accuracy: 0.969\n","epoch: 44, time: 5308.256s, loss: 0.057, train accuracy: 0.977\n","epoch: 44, time: 5313.953s, loss: 0.070, train accuracy: 0.961\n","epoch: 44, time: 5319.600s, loss: 0.126, train accuracy: 0.953\n","epoch: 44, time: 5325.377s, loss: 0.108, train accuracy: 0.977\n","epoch: 44, time: 5330.963s, loss: 0.044, train accuracy: 0.977\n","epoch: 44, time: 5336.741s, loss: 0.154, train accuracy: 0.938\n","epoch: 44, time: 5342.345s, loss: 0.057, train accuracy: 0.977\n","epoch: 44, time: 5348.117s, loss: 0.077, train accuracy: 0.977\n","Accuracy on the test set: 0.882\n","epoch: 45, time: 5358.996s, loss: 0.085, train accuracy: 0.969\n","epoch: 45, time: 5364.717s, loss: 0.109, train accuracy: 0.961\n","epoch: 45, time: 5370.343s, loss: 0.059, train accuracy: 0.977\n","epoch: 45, time: 5376.188s, loss: 0.052, train accuracy: 0.984\n","epoch: 45, time: 5381.755s, loss: 0.045, train accuracy: 0.977\n","epoch: 45, time: 5387.545s, loss: 0.075, train accuracy: 0.961\n","epoch: 45, time: 5393.165s, loss: 0.058, train accuracy: 0.969\n","epoch: 45, time: 5398.959s, loss: 0.051, train accuracy: 0.977\n","epoch: 45, time: 5404.527s, loss: 0.134, train accuracy: 0.961\n","epoch: 45, time: 5410.246s, loss: 0.064, train accuracy: 0.969\n","epoch: 45, time: 5415.953s, loss: 0.118, train accuracy: 0.969\n","epoch: 45, time: 5421.577s, loss: 0.054, train accuracy: 0.977\n","epoch: 45, time: 5427.348s, loss: 0.092, train accuracy: 0.961\n","epoch: 45, time: 5432.958s, loss: 0.019, train accuracy: 1.000\n","epoch: 45, time: 5438.800s, loss: 0.200, train accuracy: 0.914\n","epoch: 45, time: 5444.402s, loss: 0.075, train accuracy: 0.953\n","epoch: 45, time: 5450.165s, loss: 0.093, train accuracy: 0.953\n","epoch: 45, time: 5455.748s, loss: 0.063, train accuracy: 0.984\n","epoch: 45, time: 5461.417s, loss: 0.096, train accuracy: 0.953\n","epoch: 45, time: 5467.080s, loss: 0.106, train accuracy: 0.969\n","Accuracy on the test set: 0.887\n","epoch: 46, time: 5478.142s, loss: 0.053, train accuracy: 0.992\n","epoch: 46, time: 5483.727s, loss: 0.125, train accuracy: 0.953\n","epoch: 46, time: 5489.501s, loss: 0.117, train accuracy: 0.938\n","epoch: 46, time: 5495.106s, loss: 0.093, train accuracy: 0.969\n","epoch: 46, time: 5500.921s, loss: 0.077, train accuracy: 0.969\n","epoch: 46, time: 5506.514s, loss: 0.072, train accuracy: 0.977\n","epoch: 46, time: 5512.186s, loss: 0.082, train accuracy: 0.977\n","epoch: 46, time: 5517.881s, loss: 0.085, train accuracy: 0.961\n","epoch: 46, time: 5523.463s, loss: 0.154, train accuracy: 0.938\n","epoch: 46, time: 5529.239s, loss: 0.093, train accuracy: 0.961\n","epoch: 46, time: 5534.825s, loss: 0.082, train accuracy: 0.977\n","epoch: 46, time: 5540.634s, loss: 0.029, train accuracy: 0.992\n","epoch: 46, time: 5546.204s, loss: 0.031, train accuracy: 0.984\n","epoch: 46, time: 5551.977s, loss: 0.092, train accuracy: 0.969\n","epoch: 46, time: 5557.592s, loss: 0.071, train accuracy: 0.969\n","epoch: 46, time: 5563.320s, loss: 0.069, train accuracy: 0.977\n","epoch: 46, time: 5569.026s, loss: 0.028, train accuracy: 1.000\n","epoch: 46, time: 5574.617s, loss: 0.102, train accuracy: 0.977\n","epoch: 46, time: 5580.390s, loss: 0.083, train accuracy: 0.977\n","epoch: 46, time: 5585.970s, loss: 0.133, train accuracy: 0.945\n","Accuracy on the test set: 0.877\n","epoch: 47, time: 5596.935s, loss: 0.136, train accuracy: 0.945\n","epoch: 47, time: 5602.683s, loss: 0.075, train accuracy: 0.977\n","epoch: 47, time: 5608.302s, loss: 0.203, train accuracy: 0.922\n","epoch: 47, time: 5613.988s, loss: 0.124, train accuracy: 0.938\n","epoch: 47, time: 5619.694s, loss: 0.099, train accuracy: 0.961\n","epoch: 47, time: 5625.284s, loss: 0.045, train accuracy: 0.984\n","epoch: 47, time: 5631.073s, loss: 0.039, train accuracy: 0.992\n","epoch: 47, time: 5636.747s, loss: 0.077, train accuracy: 0.969\n","epoch: 47, time: 5642.553s, loss: 0.062, train accuracy: 0.977\n","epoch: 47, time: 5648.134s, loss: 0.101, train accuracy: 0.961\n","epoch: 47, time: 5653.903s, loss: 0.095, train accuracy: 0.977\n","epoch: 47, time: 5659.522s, loss: 0.061, train accuracy: 0.969\n","epoch: 47, time: 5665.181s, loss: 0.065, train accuracy: 0.977\n","epoch: 47, time: 5670.916s, loss: 0.044, train accuracy: 0.984\n","epoch: 47, time: 5676.535s, loss: 0.112, train accuracy: 0.977\n","epoch: 47, time: 5682.326s, loss: 0.134, train accuracy: 0.961\n","epoch: 47, time: 5687.928s, loss: 0.062, train accuracy: 0.984\n","epoch: 47, time: 5693.686s, loss: 0.108, train accuracy: 0.969\n","epoch: 47, time: 5699.268s, loss: 0.018, train accuracy: 0.984\n","epoch: 47, time: 5705.025s, loss: 0.130, train accuracy: 0.953\n","Accuracy on the test set: 0.880\n","epoch: 48, time: 5715.798s, loss: 0.079, train accuracy: 0.961\n","epoch: 48, time: 5721.512s, loss: 0.050, train accuracy: 0.977\n","epoch: 48, time: 5727.130s, loss: 0.054, train accuracy: 0.977\n","epoch: 48, time: 5732.920s, loss: 0.047, train accuracy: 0.984\n","epoch: 48, time: 5738.486s, loss: 0.073, train accuracy: 0.961\n","epoch: 48, time: 5744.257s, loss: 0.067, train accuracy: 0.977\n","epoch: 48, time: 5749.812s, loss: 0.074, train accuracy: 0.961\n","epoch: 48, time: 5755.562s, loss: 0.066, train accuracy: 0.984\n","epoch: 48, time: 5761.419s, loss: 0.079, train accuracy: 0.961\n","epoch: 48, time: 5767.077s, loss: 0.066, train accuracy: 0.961\n","epoch: 48, time: 5772.780s, loss: 0.039, train accuracy: 0.992\n","epoch: 48, time: 5778.367s, loss: 0.109, train accuracy: 0.961\n","epoch: 48, time: 5784.147s, loss: 0.133, train accuracy: 0.938\n","epoch: 48, time: 5789.764s, loss: 0.028, train accuracy: 0.984\n","epoch: 48, time: 5795.551s, loss: 0.089, train accuracy: 0.969\n","epoch: 48, time: 5801.146s, loss: 0.109, train accuracy: 0.977\n","epoch: 48, time: 5806.894s, loss: 0.082, train accuracy: 0.969\n","epoch: 48, time: 5812.482s, loss: 0.162, train accuracy: 0.953\n","epoch: 48, time: 5818.140s, loss: 0.064, train accuracy: 0.969\n","epoch: 48, time: 5823.814s, loss: 0.064, train accuracy: 0.969\n","Accuracy on the test set: 0.891\n","epoch: 49, time: 5834.770s, loss: 0.014, train accuracy: 0.992\n","epoch: 49, time: 5840.336s, loss: 0.058, train accuracy: 0.969\n","epoch: 49, time: 5846.110s, loss: 0.047, train accuracy: 0.984\n","epoch: 49, time: 5851.692s, loss: 0.080, train accuracy: 0.984\n","epoch: 49, time: 5857.446s, loss: 0.046, train accuracy: 0.984\n","epoch: 49, time: 5863.045s, loss: 0.035, train accuracy: 0.992\n","epoch: 49, time: 5868.712s, loss: 0.091, train accuracy: 0.984\n","epoch: 49, time: 5874.439s, loss: 0.088, train accuracy: 0.953\n","epoch: 49, time: 5880.108s, loss: 0.109, train accuracy: 0.969\n","epoch: 49, time: 5885.859s, loss: 0.064, train accuracy: 0.969\n","epoch: 49, time: 5891.449s, loss: 0.073, train accuracy: 0.961\n","epoch: 49, time: 5897.212s, loss: 0.075, train accuracy: 0.961\n","epoch: 49, time: 5902.797s, loss: 0.042, train accuracy: 0.977\n","epoch: 49, time: 5908.549s, loss: 0.059, train accuracy: 0.969\n","epoch: 49, time: 5914.167s, loss: 0.079, train accuracy: 0.984\n","epoch: 49, time: 5919.834s, loss: 0.067, train accuracy: 0.977\n","epoch: 49, time: 5925.557s, loss: 0.080, train accuracy: 0.977\n","epoch: 49, time: 5931.151s, loss: 0.070, train accuracy: 0.977\n","epoch: 49, time: 5936.917s, loss: 0.084, train accuracy: 0.969\n","epoch: 49, time: 5942.501s, loss: 0.029, train accuracy: 0.992\n","Accuracy on the test set: 0.890\n","epoch: 50, time: 5953.326s, loss: 0.020, train accuracy: 1.000\n","epoch: 50, time: 5958.995s, loss: 0.030, train accuracy: 0.992\n","epoch: 50, time: 5964.626s, loss: 0.080, train accuracy: 0.969\n","epoch: 50, time: 5970.201s, loss: 0.033, train accuracy: 0.992\n","epoch: 50, time: 5975.910s, loss: 0.059, train accuracy: 0.969\n","epoch: 50, time: 5981.462s, loss: 0.092, train accuracy: 0.969\n","epoch: 50, time: 5987.206s, loss: 0.061, train accuracy: 0.969\n","epoch: 50, time: 5992.776s, loss: 0.061, train accuracy: 0.977\n","epoch: 50, time: 5998.601s, loss: 0.045, train accuracy: 0.984\n","epoch: 50, time: 6004.179s, loss: 0.068, train accuracy: 0.984\n","epoch: 50, time: 6009.906s, loss: 0.026, train accuracy: 1.000\n","epoch: 50, time: 6015.559s, loss: 0.056, train accuracy: 0.992\n","epoch: 50, time: 6021.156s, loss: 0.054, train accuracy: 0.977\n","epoch: 50, time: 6026.898s, loss: 0.040, train accuracy: 0.984\n","epoch: 50, time: 6032.508s, loss: 0.064, train accuracy: 0.984\n","epoch: 50, time: 6038.266s, loss: 0.101, train accuracy: 0.961\n","epoch: 50, time: 6043.849s, loss: 0.036, train accuracy: 0.992\n","epoch: 50, time: 6049.653s, loss: 0.033, train accuracy: 0.984\n","epoch: 50, time: 6055.261s, loss: 0.089, train accuracy: 0.969\n","epoch: 50, time: 6061.011s, loss: 0.134, train accuracy: 0.961\n","Accuracy on the test set: 0.884\n","epoch: 51, time: 6071.760s, loss: 0.134, train accuracy: 0.953\n","epoch: 51, time: 6077.497s, loss: 0.099, train accuracy: 0.969\n","epoch: 51, time: 6083.090s, loss: 0.061, train accuracy: 0.977\n","epoch: 51, time: 6088.880s, loss: 0.071, train accuracy: 0.977\n","epoch: 51, time: 6094.480s, loss: 0.087, train accuracy: 0.992\n","epoch: 51, time: 6100.232s, loss: 0.069, train accuracy: 0.969\n","epoch: 51, time: 6105.818s, loss: 0.100, train accuracy: 0.961\n","epoch: 51, time: 6111.444s, loss: 0.056, train accuracy: 0.969\n","epoch: 51, time: 6117.115s, loss: 0.104, train accuracy: 0.969\n","epoch: 51, time: 6122.692s, loss: 0.114, train accuracy: 0.969\n","epoch: 51, time: 6128.597s, loss: 0.071, train accuracy: 0.977\n","epoch: 51, time: 6134.162s, loss: 0.103, train accuracy: 0.969\n","epoch: 51, time: 6139.917s, loss: 0.213, train accuracy: 0.938\n","epoch: 51, time: 6145.491s, loss: 0.059, train accuracy: 0.977\n","epoch: 51, time: 6151.230s, loss: 0.077, train accuracy: 0.961\n","epoch: 51, time: 6156.887s, loss: 0.100, train accuracy: 0.961\n","epoch: 51, time: 6162.517s, loss: 0.084, train accuracy: 0.977\n","epoch: 51, time: 6168.253s, loss: 0.067, train accuracy: 0.969\n","epoch: 51, time: 6173.838s, loss: 0.022, train accuracy: 0.984\n","epoch: 51, time: 6179.600s, loss: 0.035, train accuracy: 0.992\n","Accuracy on the test set: 0.890\n","epoch: 52, time: 6190.585s, loss: 0.126, train accuracy: 0.969\n","epoch: 52, time: 6196.187s, loss: 0.079, train accuracy: 0.969\n","epoch: 52, time: 6201.889s, loss: 0.124, train accuracy: 0.961\n","epoch: 52, time: 6207.576s, loss: 0.059, train accuracy: 0.984\n","epoch: 52, time: 6213.270s, loss: 0.034, train accuracy: 0.992\n","epoch: 52, time: 6219.035s, loss: 0.063, train accuracy: 0.961\n","epoch: 52, time: 6224.612s, loss: 0.018, train accuracy: 1.000\n","epoch: 52, time: 6230.414s, loss: 0.100, train accuracy: 0.977\n","epoch: 52, time: 6236.003s, loss: 0.073, train accuracy: 0.977\n","epoch: 52, time: 6241.794s, loss: 0.058, train accuracy: 0.977\n","epoch: 52, time: 6247.376s, loss: 0.031, train accuracy: 0.992\n","epoch: 52, time: 6253.102s, loss: 0.065, train accuracy: 0.984\n","epoch: 52, time: 6258.756s, loss: 0.078, train accuracy: 0.977\n","epoch: 52, time: 6264.398s, loss: 0.038, train accuracy: 0.984\n","epoch: 52, time: 6270.126s, loss: 0.061, train accuracy: 0.992\n","epoch: 52, time: 6275.727s, loss: 0.141, train accuracy: 0.938\n","epoch: 52, time: 6281.800s, loss: 0.050, train accuracy: 0.977\n","epoch: 52, time: 6287.401s, loss: 0.095, train accuracy: 0.977\n","epoch: 52, time: 6293.079s, loss: 0.067, train accuracy: 0.961\n","epoch: 52, time: 6298.745s, loss: 0.077, train accuracy: 0.969\n","Accuracy on the test set: 0.888\n","epoch: 53, time: 6309.693s, loss: 0.055, train accuracy: 0.969\n","epoch: 53, time: 6315.272s, loss: 0.062, train accuracy: 0.984\n","epoch: 53, time: 6321.023s, loss: 0.005, train accuracy: 1.000\n","epoch: 53, time: 6326.622s, loss: 0.028, train accuracy: 0.992\n","epoch: 53, time: 6332.437s, loss: 0.030, train accuracy: 0.992\n","epoch: 53, time: 6338.087s, loss: 0.040, train accuracy: 0.992\n","epoch: 53, time: 6343.753s, loss: 0.053, train accuracy: 0.977\n","epoch: 53, time: 6349.472s, loss: 0.015, train accuracy: 1.000\n","epoch: 53, time: 6355.038s, loss: 0.099, train accuracy: 0.953\n","epoch: 53, time: 6360.804s, loss: 0.083, train accuracy: 0.969\n","epoch: 53, time: 6366.379s, loss: 0.065, train accuracy: 0.984\n","epoch: 53, time: 6372.205s, loss: 0.098, train accuracy: 0.961\n","epoch: 53, time: 6377.789s, loss: 0.018, train accuracy: 1.000\n","epoch: 53, time: 6383.506s, loss: 0.129, train accuracy: 0.961\n","epoch: 53, time: 6389.105s, loss: 0.085, train accuracy: 0.977\n","epoch: 53, time: 6394.773s, loss: 0.127, train accuracy: 0.953\n","epoch: 53, time: 6400.497s, loss: 0.079, train accuracy: 0.984\n","epoch: 53, time: 6406.049s, loss: 0.019, train accuracy: 0.992\n","epoch: 53, time: 6411.776s, loss: 0.071, train accuracy: 0.977\n","epoch: 53, time: 6417.372s, loss: 0.065, train accuracy: 0.977\n","Accuracy on the test set: 0.891\n","epoch: 54, time: 6428.244s, loss: 0.026, train accuracy: 1.000\n","epoch: 54, time: 6433.947s, loss: 0.063, train accuracy: 0.984\n","epoch: 54, time: 6439.603s, loss: 0.079, train accuracy: 0.969\n","epoch: 54, time: 6445.217s, loss: 0.182, train accuracy: 0.953\n","epoch: 54, time: 6450.942s, loss: 0.051, train accuracy: 0.984\n","epoch: 54, time: 6456.526s, loss: 0.025, train accuracy: 1.000\n","epoch: 54, time: 6462.289s, loss: 0.028, train accuracy: 0.992\n","epoch: 54, time: 6467.874s, loss: 0.038, train accuracy: 0.984\n","epoch: 54, time: 6473.628s, loss: 0.044, train accuracy: 0.992\n","epoch: 54, time: 6479.203s, loss: 0.071, train accuracy: 0.969\n","epoch: 54, time: 6484.928s, loss: 0.023, train accuracy: 0.992\n","epoch: 54, time: 6490.545s, loss: 0.036, train accuracy: 0.992\n","epoch: 54, time: 6496.187s, loss: 0.066, train accuracy: 0.977\n","epoch: 54, time: 6501.898s, loss: 0.065, train accuracy: 0.969\n","epoch: 54, time: 6507.497s, loss: 0.036, train accuracy: 0.984\n","epoch: 54, time: 6513.266s, loss: 0.058, train accuracy: 0.984\n","epoch: 54, time: 6518.866s, loss: 0.151, train accuracy: 0.953\n","epoch: 54, time: 6524.625s, loss: 0.024, train accuracy: 0.992\n","epoch: 54, time: 6530.190s, loss: 0.059, train accuracy: 0.961\n","epoch: 54, time: 6535.897s, loss: 0.084, train accuracy: 0.977\n","Accuracy on the test set: 0.887\n","epoch: 55, time: 6546.564s, loss: 0.055, train accuracy: 0.984\n","epoch: 55, time: 6552.314s, loss: 0.073, train accuracy: 0.984\n","epoch: 55, time: 6557.909s, loss: 0.060, train accuracy: 0.969\n","epoch: 55, time: 6563.605s, loss: 0.032, train accuracy: 0.984\n","epoch: 55, time: 6569.193s, loss: 0.079, train accuracy: 0.984\n","epoch: 55, time: 6575.003s, loss: 0.047, train accuracy: 0.984\n","epoch: 55, time: 6580.621s, loss: 0.045, train accuracy: 0.992\n","epoch: 55, time: 6586.284s, loss: 0.018, train accuracy: 1.000\n","epoch: 55, time: 6591.929s, loss: 0.054, train accuracy: 0.977\n","epoch: 55, time: 6597.517s, loss: 0.102, train accuracy: 0.953\n","epoch: 55, time: 6603.289s, loss: 0.072, train accuracy: 0.977\n","epoch: 55, time: 6608.881s, loss: 0.040, train accuracy: 0.984\n","epoch: 55, time: 6614.695s, loss: 0.071, train accuracy: 0.969\n","epoch: 55, time: 6620.263s, loss: 0.058, train accuracy: 0.977\n","epoch: 55, time: 6625.981s, loss: 0.052, train accuracy: 0.984\n","epoch: 55, time: 6631.552s, loss: 0.087, train accuracy: 0.938\n","epoch: 55, time: 6637.234s, loss: 0.024, train accuracy: 0.992\n","epoch: 55, time: 6642.943s, loss: 0.040, train accuracy: 0.984\n","epoch: 55, time: 6648.530s, loss: 0.048, train accuracy: 0.977\n","epoch: 55, time: 6654.307s, loss: 0.025, train accuracy: 1.000\n","Accuracy on the test set: 0.884\n","epoch: 56, time: 6665.309s, loss: 0.076, train accuracy: 0.961\n","epoch: 56, time: 6670.928s, loss: 0.059, train accuracy: 0.969\n","epoch: 56, time: 6676.642s, loss: 0.076, train accuracy: 0.977\n","epoch: 56, time: 6682.257s, loss: 0.022, train accuracy: 0.992\n","epoch: 56, time: 6687.893s, loss: 0.054, train accuracy: 0.969\n","epoch: 56, time: 6693.651s, loss: 0.029, train accuracy: 0.992\n","epoch: 56, time: 6699.271s, loss: 0.066, train accuracy: 0.984\n","epoch: 56, time: 6705.046s, loss: 0.029, train accuracy: 0.992\n","epoch: 56, time: 6710.636s, loss: 0.057, train accuracy: 0.984\n","epoch: 56, time: 6716.374s, loss: 0.103, train accuracy: 0.961\n","epoch: 56, time: 6721.948s, loss: 0.054, train accuracy: 0.977\n","epoch: 56, time: 6727.691s, loss: 0.077, train accuracy: 0.969\n","epoch: 56, time: 6733.300s, loss: 0.056, train accuracy: 0.977\n","epoch: 56, time: 6738.944s, loss: 0.106, train accuracy: 0.961\n","epoch: 56, time: 6744.701s, loss: 0.042, train accuracy: 0.984\n","epoch: 56, time: 6750.287s, loss: 0.067, train accuracy: 0.977\n","epoch: 56, time: 6756.041s, loss: 0.039, train accuracy: 0.984\n","epoch: 56, time: 6761.632s, loss: 0.095, train accuracy: 0.953\n","epoch: 56, time: 6767.415s, loss: 0.062, train accuracy: 0.977\n","epoch: 56, time: 6773.013s, loss: 0.075, train accuracy: 0.969\n","Accuracy on the test set: 0.882\n","epoch: 57, time: 6783.979s, loss: 0.032, train accuracy: 0.984\n","epoch: 57, time: 6789.595s, loss: 0.092, train accuracy: 0.961\n","epoch: 57, time: 6795.352s, loss: 0.047, train accuracy: 0.969\n","epoch: 57, time: 6800.936s, loss: 0.066, train accuracy: 0.977\n","epoch: 57, time: 6806.816s, loss: 0.075, train accuracy: 0.977\n","epoch: 57, time: 6812.583s, loss: 0.082, train accuracy: 0.984\n","epoch: 57, time: 6818.369s, loss: 0.047, train accuracy: 0.984\n","epoch: 57, time: 6823.961s, loss: 0.036, train accuracy: 0.992\n","epoch: 57, time: 6829.735s, loss: 0.107, train accuracy: 0.969\n","epoch: 57, time: 6835.355s, loss: 0.093, train accuracy: 0.969\n","epoch: 57, time: 6841.020s, loss: 0.077, train accuracy: 0.969\n","epoch: 57, time: 6846.746s, loss: 0.079, train accuracy: 0.969\n","epoch: 57, time: 6852.318s, loss: 0.057, train accuracy: 0.984\n","epoch: 57, time: 6858.189s, loss: 0.122, train accuracy: 0.961\n","epoch: 57, time: 6863.760s, loss: 0.015, train accuracy: 1.000\n","epoch: 57, time: 6869.515s, loss: 0.097, train accuracy: 0.977\n","epoch: 57, time: 6875.090s, loss: 0.196, train accuracy: 0.945\n","epoch: 57, time: 6880.802s, loss: 0.062, train accuracy: 0.984\n","epoch: 57, time: 6886.442s, loss: 0.077, train accuracy: 0.977\n","epoch: 57, time: 6892.055s, loss: 0.079, train accuracy: 0.969\n","Accuracy on the test set: 0.883\n","epoch: 58, time: 6902.864s, loss: 0.079, train accuracy: 0.977\n","epoch: 58, time: 6908.642s, loss: 0.025, train accuracy: 0.992\n","epoch: 58, time: 6914.293s, loss: 0.077, train accuracy: 0.969\n","epoch: 58, time: 6920.128s, loss: 0.061, train accuracy: 0.984\n","epoch: 58, time: 6925.705s, loss: 0.013, train accuracy: 1.000\n","epoch: 58, time: 6931.459s, loss: 0.038, train accuracy: 0.984\n","epoch: 58, time: 6937.200s, loss: 0.039, train accuracy: 0.992\n","epoch: 58, time: 6942.806s, loss: 0.051, train accuracy: 0.977\n","epoch: 58, time: 6948.623s, loss: 0.071, train accuracy: 0.977\n","epoch: 58, time: 6954.232s, loss: 0.054, train accuracy: 0.992\n","epoch: 58, time: 6960.075s, loss: 0.079, train accuracy: 0.961\n","epoch: 58, time: 6965.664s, loss: 0.063, train accuracy: 0.984\n","epoch: 58, time: 6971.485s, loss: 0.045, train accuracy: 0.977\n","epoch: 58, time: 6977.120s, loss: 0.045, train accuracy: 0.992\n","epoch: 58, time: 6982.881s, loss: 0.068, train accuracy: 0.977\n","epoch: 58, time: 6988.608s, loss: 0.066, train accuracy: 0.977\n","epoch: 58, time: 6994.240s, loss: 0.036, train accuracy: 0.992\n","epoch: 58, time: 7000.020s, loss: 0.061, train accuracy: 0.984\n","epoch: 58, time: 7005.622s, loss: 0.013, train accuracy: 1.000\n","epoch: 58, time: 7011.429s, loss: 0.056, train accuracy: 0.977\n","Accuracy on the test set: 0.888\n","epoch: 59, time: 7022.591s, loss: 0.039, train accuracy: 0.992\n","epoch: 59, time: 7028.160s, loss: 0.011, train accuracy: 1.000\n","epoch: 59, time: 7033.870s, loss: 0.048, train accuracy: 0.977\n","epoch: 59, time: 7039.582s, loss: 0.015, train accuracy: 1.000\n","epoch: 59, time: 7045.224s, loss: 0.056, train accuracy: 0.977\n","epoch: 59, time: 7051.061s, loss: 0.041, train accuracy: 0.984\n","epoch: 59, time: 7056.690s, loss: 0.027, train accuracy: 0.992\n","epoch: 59, time: 7062.493s, loss: 0.059, train accuracy: 0.984\n","epoch: 59, time: 7068.126s, loss: 0.041, train accuracy: 0.984\n","epoch: 59, time: 7073.939s, loss: 0.037, train accuracy: 0.977\n","epoch: 59, time: 7079.539s, loss: 0.030, train accuracy: 0.984\n","epoch: 59, time: 7085.254s, loss: 0.128, train accuracy: 0.953\n","epoch: 59, time: 7090.967s, loss: 0.060, train accuracy: 0.969\n","epoch: 59, time: 7096.615s, loss: 0.032, train accuracy: 1.000\n","epoch: 59, time: 7102.411s, loss: 0.098, train accuracy: 0.969\n","epoch: 59, time: 7108.034s, loss: 0.117, train accuracy: 0.953\n","epoch: 59, time: 7113.837s, loss: 0.086, train accuracy: 0.961\n","epoch: 59, time: 7119.450s, loss: 0.095, train accuracy: 0.969\n","epoch: 59, time: 7125.205s, loss: 0.079, train accuracy: 0.969\n","epoch: 59, time: 7130.827s, loss: 0.043, train accuracy: 0.992\n","Accuracy on the test set: 0.890\n","epoch: 60, time: 7141.886s, loss: 0.077, train accuracy: 0.977\n","epoch: 60, time: 7147.501s, loss: 0.057, train accuracy: 0.977\n","epoch: 60, time: 7153.298s, loss: 0.029, train accuracy: 0.984\n","epoch: 60, time: 7158.916s, loss: 0.066, train accuracy: 0.977\n","epoch: 60, time: 7164.799s, loss: 0.045, train accuracy: 0.984\n","epoch: 60, time: 7170.405s, loss: 0.036, train accuracy: 0.984\n","epoch: 60, time: 7176.163s, loss: 0.046, train accuracy: 0.984\n","epoch: 60, time: 7181.810s, loss: 0.021, train accuracy: 0.992\n","epoch: 60, time: 7187.458s, loss: 0.040, train accuracy: 1.000\n","epoch: 60, time: 7193.200s, loss: 0.051, train accuracy: 0.977\n","epoch: 60, time: 7198.806s, loss: 0.120, train accuracy: 0.953\n","epoch: 60, time: 7204.586s, loss: 0.120, train accuracy: 0.961\n","epoch: 60, time: 7210.197s, loss: 0.062, train accuracy: 0.977\n","epoch: 60, time: 7215.983s, loss: 0.040, train accuracy: 0.977\n","epoch: 60, time: 7221.574s, loss: 0.026, train accuracy: 0.992\n","epoch: 60, time: 7227.305s, loss: 0.040, train accuracy: 0.984\n","epoch: 60, time: 7232.901s, loss: 0.107, train accuracy: 0.961\n","epoch: 60, time: 7238.581s, loss: 0.109, train accuracy: 0.953\n","epoch: 60, time: 7244.284s, loss: 0.074, train accuracy: 0.977\n","epoch: 60, time: 7249.910s, loss: 0.060, train accuracy: 0.977\n","Accuracy on the test set: 0.889\n","epoch: 61, time: 7260.853s, loss: 0.079, train accuracy: 0.969\n","epoch: 61, time: 7266.677s, loss: 0.022, train accuracy: 1.000\n","epoch: 61, time: 7272.288s, loss: 0.021, train accuracy: 0.992\n","epoch: 61, time: 7278.062s, loss: 0.053, train accuracy: 0.969\n","epoch: 61, time: 7283.821s, loss: 0.075, train accuracy: 0.961\n","epoch: 61, time: 7289.469s, loss: 0.032, train accuracy: 0.992\n","epoch: 61, time: 7295.230s, loss: 0.022, train accuracy: 1.000\n","epoch: 61, time: 7300.822s, loss: 0.040, train accuracy: 0.984\n","epoch: 61, time: 7306.639s, loss: 0.043, train accuracy: 0.992\n","epoch: 61, time: 7312.283s, loss: 0.039, train accuracy: 0.984\n","epoch: 61, time: 7318.052s, loss: 0.057, train accuracy: 0.977\n","epoch: 61, time: 7323.678s, loss: 0.121, train accuracy: 0.953\n","epoch: 61, time: 7329.609s, loss: 0.009, train accuracy: 1.000\n","epoch: 61, time: 7335.424s, loss: 0.072, train accuracy: 0.977\n","epoch: 61, time: 7341.029s, loss: 0.028, train accuracy: 1.000\n","epoch: 61, time: 7346.823s, loss: 0.164, train accuracy: 0.969\n","epoch: 61, time: 7352.420s, loss: 0.072, train accuracy: 0.977\n","epoch: 61, time: 7358.228s, loss: 0.031, train accuracy: 0.984\n","epoch: 61, time: 7363.814s, loss: 0.073, train accuracy: 0.969\n","epoch: 61, time: 7369.568s, loss: 0.068, train accuracy: 0.984\n","Accuracy on the test set: 0.890\n","epoch: 62, time: 7380.385s, loss: 0.031, train accuracy: 0.984\n","epoch: 62, time: 7386.175s, loss: 0.064, train accuracy: 0.977\n","epoch: 62, time: 7391.783s, loss: 0.131, train accuracy: 0.961\n","epoch: 62, time: 7397.548s, loss: 0.080, train accuracy: 0.969\n","epoch: 62, time: 7403.182s, loss: 0.060, train accuracy: 0.992\n","epoch: 62, time: 7408.936s, loss: 0.060, train accuracy: 0.984\n","epoch: 62, time: 7414.569s, loss: 0.181, train accuracy: 0.945\n","epoch: 62, time: 7420.309s, loss: 0.033, train accuracy: 0.992\n","epoch: 62, time: 7426.026s, loss: 0.025, train accuracy: 1.000\n","epoch: 62, time: 7431.648s, loss: 0.107, train accuracy: 0.945\n","epoch: 62, time: 7437.427s, loss: 0.028, train accuracy: 0.992\n","epoch: 62, time: 7443.033s, loss: 0.035, train accuracy: 0.977\n","epoch: 62, time: 7448.828s, loss: 0.022, train accuracy: 1.000\n","epoch: 62, time: 7454.448s, loss: 0.062, train accuracy: 0.961\n","epoch: 62, time: 7460.287s, loss: 0.105, train accuracy: 0.969\n","epoch: 62, time: 7465.900s, loss: 0.106, train accuracy: 0.969\n","epoch: 62, time: 7471.631s, loss: 0.064, train accuracy: 0.984\n","epoch: 62, time: 7477.321s, loss: 0.058, train accuracy: 0.984\n","epoch: 62, time: 7482.975s, loss: 0.025, train accuracy: 0.984\n","epoch: 62, time: 7488.754s, loss: 0.073, train accuracy: 0.977\n","Accuracy on the test set: 0.895\n","epoch: 63, time: 7499.881s, loss: 0.052, train accuracy: 0.984\n","epoch: 63, time: 7505.499s, loss: 0.018, train accuracy: 0.992\n","epoch: 63, time: 7511.299s, loss: 0.032, train accuracy: 0.992\n","epoch: 63, time: 7516.898s, loss: 0.189, train accuracy: 0.945\n","epoch: 63, time: 7522.625s, loss: 0.041, train accuracy: 0.977\n","epoch: 63, time: 7528.388s, loss: 0.066, train accuracy: 0.969\n","epoch: 63, time: 7533.983s, loss: 0.073, train accuracy: 0.953\n","epoch: 63, time: 7539.819s, loss: 0.019, train accuracy: 1.000\n","epoch: 63, time: 7545.437s, loss: 0.043, train accuracy: 0.984\n","epoch: 63, time: 7551.244s, loss: 0.019, train accuracy: 1.000\n","epoch: 63, time: 7556.887s, loss: 0.016, train accuracy: 1.000\n","epoch: 63, time: 7562.768s, loss: 0.043, train accuracy: 0.992\n","epoch: 63, time: 7568.390s, loss: 0.115, train accuracy: 0.953\n","epoch: 63, time: 7574.077s, loss: 0.027, train accuracy: 0.984\n","epoch: 63, time: 7579.767s, loss: 0.068, train accuracy: 0.984\n","epoch: 63, time: 7585.397s, loss: 0.092, train accuracy: 0.977\n","epoch: 63, time: 7591.202s, loss: 0.012, train accuracy: 1.000\n","epoch: 63, time: 7596.804s, loss: 0.029, train accuracy: 0.984\n","epoch: 63, time: 7602.630s, loss: 0.016, train accuracy: 0.992\n","epoch: 63, time: 7608.259s, loss: 0.064, train accuracy: 0.977\n","Accuracy on the test set: 0.893\n","epoch: 64, time: 7619.396s, loss: 0.007, train accuracy: 1.000\n","epoch: 64, time: 7625.064s, loss: 0.010, train accuracy: 1.000\n","epoch: 64, time: 7630.783s, loss: 0.020, train accuracy: 1.000\n","epoch: 64, time: 7636.393s, loss: 0.059, train accuracy: 0.984\n","epoch: 64, time: 7642.189s, loss: 0.043, train accuracy: 0.984\n","epoch: 64, time: 7647.804s, loss: 0.021, train accuracy: 0.992\n","epoch: 64, time: 7653.618s, loss: 0.061, train accuracy: 0.977\n","epoch: 64, time: 7659.243s, loss: 0.059, train accuracy: 0.969\n","epoch: 64, time: 7664.981s, loss: 0.070, train accuracy: 0.969\n","epoch: 64, time: 7670.680s, loss: 0.060, train accuracy: 0.977\n","epoch: 64, time: 7676.326s, loss: 0.038, train accuracy: 0.984\n","epoch: 64, time: 7682.061s, loss: 0.033, train accuracy: 0.977\n","epoch: 64, time: 7687.663s, loss: 0.078, train accuracy: 0.977\n","epoch: 64, time: 7693.479s, loss: 0.030, train accuracy: 0.992\n","epoch: 64, time: 7699.096s, loss: 0.047, train accuracy: 0.992\n","epoch: 64, time: 7704.900s, loss: 0.037, train accuracy: 0.984\n","epoch: 64, time: 7710.549s, loss: 0.108, train accuracy: 0.953\n","epoch: 64, time: 7716.351s, loss: 0.084, train accuracy: 0.969\n","epoch: 64, time: 7722.016s, loss: 0.065, train accuracy: 0.969\n","epoch: 64, time: 7727.704s, loss: 0.046, train accuracy: 0.977\n","Accuracy on the test set: 0.893\n","epoch: 65, time: 7738.719s, loss: 0.066, train accuracy: 0.977\n","epoch: 65, time: 7744.587s, loss: 0.061, train accuracy: 0.969\n","epoch: 65, time: 7750.209s, loss: 0.062, train accuracy: 0.977\n","epoch: 65, time: 7756.050s, loss: 0.036, train accuracy: 0.984\n","epoch: 65, time: 7761.690s, loss: 0.044, train accuracy: 0.984\n","epoch: 65, time: 7767.459s, loss: 0.080, train accuracy: 0.984\n","epoch: 65, time: 7773.177s, loss: 0.019, train accuracy: 0.992\n","epoch: 65, time: 7778.872s, loss: 0.070, train accuracy: 0.984\n","epoch: 65, time: 7784.691s, loss: 0.023, train accuracy: 0.992\n","epoch: 65, time: 7790.382s, loss: 0.076, train accuracy: 0.977\n","epoch: 65, time: 7796.179s, loss: 0.047, train accuracy: 0.984\n","epoch: 65, time: 7801.882s, loss: 0.047, train accuracy: 0.984\n","epoch: 65, time: 7807.733s, loss: 0.029, train accuracy: 0.992\n","epoch: 65, time: 7813.356s, loss: 0.108, train accuracy: 0.961\n","epoch: 65, time: 7819.185s, loss: 0.055, train accuracy: 0.984\n","epoch: 65, time: 7824.869s, loss: 0.043, train accuracy: 0.992\n","epoch: 65, time: 7830.586s, loss: 0.075, train accuracy: 0.961\n","epoch: 65, time: 7836.368s, loss: 0.043, train accuracy: 0.984\n","epoch: 65, time: 7841.981s, loss: 0.027, train accuracy: 0.992\n","epoch: 65, time: 7847.870s, loss: 0.085, train accuracy: 0.945\n","Accuracy on the test set: 0.883\n","epoch: 66, time: 7859.073s, loss: 0.063, train accuracy: 0.977\n","epoch: 66, time: 7864.712s, loss: 0.041, train accuracy: 0.984\n","epoch: 66, time: 7870.491s, loss: 0.081, train accuracy: 0.977\n","epoch: 66, time: 7876.196s, loss: 0.113, train accuracy: 0.969\n","epoch: 66, time: 7882.094s, loss: 0.043, train accuracy: 0.992\n","epoch: 66, time: 7887.983s, loss: 0.067, train accuracy: 0.969\n","epoch: 66, time: 7893.642s, loss: 0.058, train accuracy: 0.984\n","epoch: 66, time: 7899.487s, loss: 0.046, train accuracy: 0.992\n","epoch: 66, time: 7905.139s, loss: 0.088, train accuracy: 0.984\n","epoch: 66, time: 7910.978s, loss: 0.071, train accuracy: 0.984\n","epoch: 66, time: 7916.647s, loss: 0.027, train accuracy: 0.984\n","epoch: 66, time: 7922.363s, loss: 0.077, train accuracy: 0.984\n","epoch: 66, time: 7928.104s, loss: 0.046, train accuracy: 0.977\n","epoch: 66, time: 7933.719s, loss: 0.048, train accuracy: 0.969\n","epoch: 66, time: 7939.577s, loss: 0.028, train accuracy: 0.992\n","epoch: 66, time: 7945.230s, loss: 0.116, train accuracy: 0.961\n","epoch: 66, time: 7951.077s, loss: 0.048, train accuracy: 0.977\n","epoch: 66, time: 7956.726s, loss: 0.034, train accuracy: 0.969\n","epoch: 66, time: 7962.533s, loss: 0.047, train accuracy: 0.984\n","epoch: 66, time: 7968.190s, loss: 0.071, train accuracy: 0.969\n","Accuracy on the test set: 0.894\n","epoch: 67, time: 7979.368s, loss: 0.081, train accuracy: 0.977\n","epoch: 67, time: 7984.989s, loss: 0.047, train accuracy: 0.984\n","epoch: 67, time: 7990.840s, loss: 0.063, train accuracy: 0.969\n","epoch: 67, time: 7996.465s, loss: 0.036, train accuracy: 0.984\n","epoch: 67, time: 8002.282s, loss: 0.020, train accuracy: 0.992\n","epoch: 67, time: 8007.900s, loss: 0.014, train accuracy: 0.992\n","epoch: 67, time: 8013.719s, loss: 0.017, train accuracy: 1.000\n","epoch: 67, time: 8019.400s, loss: 0.033, train accuracy: 0.984\n","epoch: 67, time: 8025.132s, loss: 0.047, train accuracy: 0.977\n","epoch: 67, time: 8030.861s, loss: 0.077, train accuracy: 0.969\n","epoch: 67, time: 8036.503s, loss: 0.044, train accuracy: 0.977\n","epoch: 67, time: 8042.428s, loss: 0.038, train accuracy: 0.984\n","epoch: 67, time: 8048.063s, loss: 0.039, train accuracy: 0.992\n","epoch: 67, time: 8053.929s, loss: 0.043, train accuracy: 0.977\n","epoch: 67, time: 8059.524s, loss: 0.057, train accuracy: 0.984\n","epoch: 67, time: 8065.332s, loss: 0.029, train accuracy: 0.984\n","epoch: 67, time: 8070.973s, loss: 0.060, train accuracy: 0.977\n","epoch: 67, time: 8076.699s, loss: 0.121, train accuracy: 0.969\n","epoch: 67, time: 8082.470s, loss: 0.039, train accuracy: 0.977\n","epoch: 67, time: 8088.099s, loss: 0.042, train accuracy: 0.977\n","Accuracy on the test set: 0.890\n","epoch: 68, time: 8099.176s, loss: 0.012, train accuracy: 0.992\n","epoch: 68, time: 8104.996s, loss: 0.086, train accuracy: 0.977\n","epoch: 68, time: 8110.643s, loss: 0.030, train accuracy: 0.992\n","epoch: 68, time: 8116.475s, loss: 0.058, train accuracy: 0.984\n","epoch: 68, time: 8122.164s, loss: 0.030, train accuracy: 0.984\n","epoch: 68, time: 8127.861s, loss: 0.070, train accuracy: 0.977\n","epoch: 68, time: 8133.630s, loss: 0.021, train accuracy: 0.992\n","epoch: 68, time: 8139.266s, loss: 0.046, train accuracy: 0.984\n","epoch: 68, time: 8145.099s, loss: 0.060, train accuracy: 0.992\n","epoch: 68, time: 8150.776s, loss: 0.033, train accuracy: 0.984\n","epoch: 68, time: 8156.629s, loss: 0.038, train accuracy: 0.984\n","epoch: 68, time: 8162.249s, loss: 0.043, train accuracy: 0.984\n","epoch: 68, time: 8168.119s, loss: 0.030, train accuracy: 0.992\n","epoch: 68, time: 8173.758s, loss: 0.061, train accuracy: 0.961\n","epoch: 68, time: 8179.503s, loss: 0.088, train accuracy: 0.969\n","epoch: 68, time: 8185.266s, loss: 0.051, train accuracy: 0.984\n","epoch: 68, time: 8190.912s, loss: 0.046, train accuracy: 0.984\n","epoch: 68, time: 8196.775s, loss: 0.030, train accuracy: 0.992\n","epoch: 68, time: 8202.420s, loss: 0.062, train accuracy: 0.969\n","epoch: 68, time: 8208.230s, loss: 0.040, train accuracy: 0.977\n","Accuracy on the test set: 0.889\n","epoch: 69, time: 8219.388s, loss: 0.046, train accuracy: 0.977\n","epoch: 69, time: 8225.039s, loss: 0.029, train accuracy: 0.992\n","epoch: 69, time: 8230.735s, loss: 0.054, train accuracy: 0.969\n","epoch: 69, time: 8236.496s, loss: 0.011, train accuracy: 0.992\n","epoch: 69, time: 8242.123s, loss: 0.043, train accuracy: 0.992\n","epoch: 69, time: 8247.938s, loss: 0.015, train accuracy: 1.000\n","epoch: 69, time: 8253.574s, loss: 0.079, train accuracy: 0.969\n","epoch: 69, time: 8259.387s, loss: 0.062, train accuracy: 0.969\n","epoch: 69, time: 8264.977s, loss: 0.076, train accuracy: 0.977\n","epoch: 69, time: 8270.776s, loss: 0.056, train accuracy: 0.977\n","epoch: 69, time: 8276.416s, loss: 0.068, train accuracy: 0.969\n","epoch: 69, time: 8282.168s, loss: 0.028, train accuracy: 0.992\n","epoch: 69, time: 8287.892s, loss: 0.040, train accuracy: 0.992\n","epoch: 69, time: 8293.495s, loss: 0.011, train accuracy: 1.000\n","epoch: 69, time: 8299.308s, loss: 0.093, train accuracy: 0.969\n","epoch: 69, time: 8304.924s, loss: 0.055, train accuracy: 0.977\n","epoch: 69, time: 8310.814s, loss: 0.050, train accuracy: 0.984\n","epoch: 69, time: 8316.421s, loss: 0.041, train accuracy: 0.984\n","epoch: 69, time: 8322.241s, loss: 0.038, train accuracy: 0.992\n","epoch: 69, time: 8327.944s, loss: 0.004, train accuracy: 1.000\n","Accuracy on the test set: 0.891\n","epoch: 70, time: 8339.090s, loss: 0.101, train accuracy: 0.977\n","epoch: 70, time: 8344.706s, loss: 0.111, train accuracy: 0.977\n","epoch: 70, time: 8350.550s, loss: 0.117, train accuracy: 0.969\n","epoch: 70, time: 8356.153s, loss: 0.110, train accuracy: 0.953\n","epoch: 70, time: 8361.991s, loss: 0.045, train accuracy: 0.977\n","epoch: 70, time: 8367.637s, loss: 0.025, train accuracy: 0.992\n","epoch: 70, time: 8373.433s, loss: 0.023, train accuracy: 0.992\n","epoch: 70, time: 8379.129s, loss: 0.044, train accuracy: 0.984\n","epoch: 70, time: 8384.811s, loss: 0.080, train accuracy: 0.961\n","epoch: 70, time: 8390.617s, loss: 0.026, train accuracy: 0.992\n","epoch: 70, time: 8396.220s, loss: 0.031, train accuracy: 0.992\n","epoch: 70, time: 8402.046s, loss: 0.019, train accuracy: 0.992\n","epoch: 70, time: 8407.662s, loss: 0.026, train accuracy: 0.984\n","epoch: 70, time: 8413.490s, loss: 0.016, train accuracy: 0.992\n","epoch: 70, time: 8419.119s, loss: 0.040, train accuracy: 0.992\n","epoch: 70, time: 8424.875s, loss: 0.018, train accuracy: 1.000\n","epoch: 70, time: 8430.571s, loss: 0.025, train accuracy: 0.984\n","epoch: 70, time: 8436.256s, loss: 0.060, train accuracy: 0.984\n","epoch: 70, time: 8442.043s, loss: 0.029, train accuracy: 0.984\n","epoch: 70, time: 8447.677s, loss: 0.035, train accuracy: 0.984\n","Accuracy on the test set: 0.890\n","epoch: 71, time: 8459.281s, loss: 0.032, train accuracy: 1.000\n","epoch: 71, time: 8465.098s, loss: 0.052, train accuracy: 0.984\n","epoch: 71, time: 8470.744s, loss: 0.028, train accuracy: 0.984\n","epoch: 71, time: 8476.549s, loss: 0.013, train accuracy: 1.000\n","epoch: 71, time: 8482.245s, loss: 0.044, train accuracy: 0.977\n","epoch: 71, time: 8487.933s, loss: 0.031, train accuracy: 0.992\n","epoch: 71, time: 8493.714s, loss: 0.061, train accuracy: 0.969\n","epoch: 71, time: 8499.331s, loss: 0.126, train accuracy: 0.977\n","epoch: 71, time: 8505.146s, loss: 0.075, train accuracy: 0.984\n","epoch: 71, time: 8510.782s, loss: 0.088, train accuracy: 0.984\n","epoch: 71, time: 8516.612s, loss: 0.069, train accuracy: 0.961\n","epoch: 71, time: 8522.306s, loss: 0.046, train accuracy: 0.984\n","epoch: 71, time: 8528.090s, loss: 0.033, train accuracy: 0.984\n","epoch: 71, time: 8533.752s, loss: 0.052, train accuracy: 0.984\n","epoch: 71, time: 8539.430s, loss: 0.036, train accuracy: 0.984\n","epoch: 71, time: 8545.214s, loss: 0.055, train accuracy: 0.969\n","epoch: 71, time: 8550.829s, loss: 0.045, train accuracy: 0.977\n","epoch: 71, time: 8556.658s, loss: 0.028, train accuracy: 0.992\n","epoch: 71, time: 8562.254s, loss: 0.021, train accuracy: 1.000\n","epoch: 71, time: 8568.036s, loss: 0.089, train accuracy: 0.977\n","Accuracy on the test set: 0.890\n","epoch: 72, time: 8579.045s, loss: 0.013, train accuracy: 1.000\n","epoch: 72, time: 8584.729s, loss: 0.012, train accuracy: 1.000\n","epoch: 72, time: 8590.361s, loss: 0.112, train accuracy: 0.961\n","epoch: 72, time: 8596.137s, loss: 0.020, train accuracy: 0.992\n","epoch: 72, time: 8601.761s, loss: 0.151, train accuracy: 0.953\n"]}],"source":["start = time.time()\n","\n","# define lists that store train and test accuracy for each epoch\n","\n","train_acc = []\n","test_acc = []\n","\n","for epoch in range(0, 200):\n","\n","    # initialize number of correct train predictions for the current epoch\n","\n","    correct_train_total = 0\n","\n","    net.train()  # Put the network in train mode\n","    for i, (x_batch, y_batch) in enumerate(trainloader):\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(\n","            device\n","        )  # Move the data to the device that is used\n","\n","        optimizer.zero_grad()  # Set all currenly stored gradients to zero\n","\n","        y_pred = net(x_batch)\n","\n","        loss = criterion(y_pred, y_batch)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        # Compute relevant metrics\n","\n","        y_pred_max = torch.argmax(\n","            y_pred, dim=1\n","        )  # Get the labels with highest output probability\n","\n","        correct = torch.sum(\n","            torch.eq(y_pred_max, y_batch)\n","        ).item()  # Count how many are equal to the true labels\n","\n","        elapsed = time.time() - start  # Keep track of how much time has elapsed\n","\n","        # accumulate number of correct predictions\n","\n","        correct_train_total += correct\n","\n","        # Show progress every 20 batches\n","\n","        if not i % 20:\n","            print(\n","                f\"epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}\"\n","            )\n","        correct_total = 0\n","    # store train accuracy for current epoch\n","\n","    train_acc.append(correct_train_total / len(trainset))\n","\n","    net.eval()  # Put the network in eval mode\n","    for i, (x_batch, y_batch) in enumerate(testloader):\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(\n","            device\n","        )  # Move the data to the device that is used\n","\n","        y_pred = net(x_batch)\n","        y_pred_max = torch.argmax(y_pred, dim=1)\n","\n","        correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n","    print(f\"Accuracy on the test set: {correct_total / len(testset):.3f}\")\n","\n","    # store test accuracy for current epoch\n","\n","    test_acc.append(correct_total / len(testset))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0jcJkRe8T7BW"},"outputs":[],"source":["correct_total = 0\n","\n","for i, (x_batch, y_batch) in enumerate(testloader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(\n","        device\n","    )  # Move the data to the device that is used\n","\n","    y_pred = net(x_batch)\n","    y_pred_max = torch.argmax(y_pred, dim=1)\n","\n","    correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\n","print(f\"Accuracy on the test set: {correct_total / len(testset):.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h0al93BEle6C"},"outputs":[],"source":["plt.plot(range(len(train_acc)), train_acc)\n","plt.plot(range(len(test_acc)), test_acc)\n","plt.legend([\"train\", \"test\"])\n","plt.xlabel(\"epoch number\")\n","plt.ylabel(\"accuracy\")\n","plt.title(\"Train and test accuracy evolution\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
